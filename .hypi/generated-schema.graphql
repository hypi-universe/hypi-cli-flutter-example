# This file was generated based on ".graphqlconfig". Do not edit manually.

schema {
    query: Query
    mutation: Mutation
    subscription: Subscription
}

"""

Based on http://www.tsusiatsoftware.net/
See Geometry Model at http://www.tsusiatsoftware.net/jts/jtsfeatures.html
http://www.tsusiatsoftware.net/jts/javadoc/com/vividsolutions/jts/geom/Geometry.html
Defines a rectangular region of the 2D coordinate plane. It is often used to represent the bounding box of a Geometry, e.g. the minimum and maximum x and y values of the Coordinates.
todo define specific subtypes of Geo and supporting types
http://www.tsusiatsoftware.net/jts/javadoc/com/vividsolutions/jts/geom/PrecisionModel.html
http://www.tsusiatsoftware.net/jts/javadoc/com/vividsolutions/jts/geom/Point.html
http://www.tsusiatsoftware.net/jts/javadoc/com/vividsolutions/jts/geom/MultiPoint.html
http://www.tsusiatsoftware.net/jts/javadoc/com/vividsolutions/jts/geom/LineString.html
http://www.tsusiatsoftware.net/jts/javadoc/com/vividsolutions/jts/geom/MultiLineString.html
http://www.tsusiatsoftware.net/jts/javadoc/com/vividsolutions/jts/geom/Polygon.html
http://www.tsusiatsoftware.net/jts/javadoc/com/vividsolutions/jts/geom/MultiPolygon.html
http://www.tsusiatsoftware.net/jts/javadoc/com/vividsolutions/jts/geom/GeometryCollection.html
"""
interface Geo {
    envelope: GeoEnvelope
    hypi: Hypi
    srid: Int
}

interface HttpResponse {
    headers: Json
    hypi: Hypi
    rawPayload: String
    status: Int
}

interface Policy {
    hypi: Hypi
    "Positive` or `Negative"
    logic: AuthLogic
    name: String!
}

interface WorkflowAsync {
    async: Boolean
    hypi: Hypi
}

"""

Indicates the type should only be evaluated IFF the refrenced function is defined AND executing it returns true.
Any other state results in the evaluation of the conditional e.g.
if evaluateIf is not defined, the conditional is executed.
if evaluateIf is defined but returns anything other than the boolean value true the conditional is executed
"""
interface WorkflowConditional {
    evaluateIf: GraphQLRef
    hypi: Hypi
}

interface WorkflowExecutableAs {
    """

    An ArcQL query to find the account e.g. hypi.id = 'user123' to find by id or username = 'blah' to find by username
    If present, execution of the steps in the Workflow will be done as this account
    If not specified, it defaults to the account making the request
    """
    execAs: String
    hypi: Hypi
}

interface WorkflowOrdered {
    hypi: Hypi
    order: Int!
}

interface WorkflowParallel {
    hypi: Hypi
    "If present AND true, all steps in this block are executed at the same time."
    parallel: Boolean
}

"""

Indicates the type should be repeated once it's finished IFF the referenced function is defined AND executing it returns true;
repeatIf and repeatN are mutually exclusive. If repeatN is specified it takes precedence over repeatIf
"""
interface WorkflowRepeatable {
    hypi: Hypi
    repeatIf: GraphQLRef
    repeatN: Int
}

interface WorkflowTimed {
    hypi: Hypi
    """

    Specifies the the max time an async task should be allowed to execute. When this time has elapsed the task will be killed.
    The format is ISO8601 durations https://en.wikipedia.org/wiki/ISO_8601#Durations
    e.g. P1M is 1 month and PT1M is 1 minute
    """
    maxExecutionTime: String
}

"A union of all types in the app which can be created or updated directly"
union HypiRootAggregate = AccessToken | Account | AccountPolicy | Address | AggFloat | AggInt | AggOtherScalar | AggregatedPolicy | AppId | AuthClient | BruteForceDetectionOptions | ClientPolicy | Coordinate | Counter | Country | Currency | Email | EmailMessage | EmailSendingAttempt | EmailTemplate | EmailVerification | File | Gauge | GeoEnvelope | GraphQLRef | Group | GroupPolicy | Hypi | HypiEnv | HypiFilterConnection | HypiResultEdge | Image | Language | LogMessage | LoginAttempt | Notification | NotificationCtx | OAuth2AuthorizedClient | OAuthProvider | Organisation | PageInfo | Pair | Password | PasswordReminder | Permission | PermissionDescription | Person | PersonName | Phone | Product | Realm | RealmLink | RealmPolicy | RemoteLogin | RequestTemplate | Role | RolePolicy | Script | ServerlessResponse | TimePolicy | URL | Video | Webhook | WebhookResponse | Workflow | WorkflowSession | WorkflowStep | WorkflowStepData

type AccessToken {
    errorCode: String
    errorMsg: String
    hypi: Hypi
    sessionExpires: Long
    sessionToken: String
}

type AccessTokenAggs {
    errorCode: AggOtherScalar
    errorMsg: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    sessionExpires: AggOtherScalar
    sessionToken: AggOtherScalar
}

type Account {
    attempts(after: String, arcql: String, before: String, first: Int, last: Int): [LoginAttempt!]
    emails(after: String, arcql: String, before: String, first: Int, last: Int): [Email!]
    enabled: Boolean
    groups(after: String, arcql: String, before: String, first: Int, last: Int): [Group!]
    hypi: Hypi
    owner: Person
    password: Password!
    phones(after: String, arcql: String, before: String, first: Int, last: Int): [Phone!]
    remoteLogins(after: String, arcql: String, before: String, first: Int, last: Int): [RemoteLogin!]
    roles(after: String, arcql: String, before: String, first: Int, last: Int): [Role!]
    username: String!
    verified: Boolean
}

type AccountAggs {
    enabled: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    username: AggOtherScalar
    verified: AggOtherScalar
}

type AccountPolicy implements Policy {
    accounts(after: String, arcql: String, before: String, first: Int, last: Int): [Account!]
    hypi: Hypi
    "Positive` or `Negative"
    logic: AuthLogic
    name: String!
}

type AccountPolicyAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    logic: AggOtherScalar
    name: AggOtherScalar
}

type Address {
    city: String
    country: Country
    county: String
    door: String
    "  country: Country"
    from: DateTime
    hypi: Hypi
    postCode: String
    street: String
    to: DateTime
    town: String
}

type AddressAggs {
    city: AggOtherScalar
    county: AggOtherScalar
    door: AggOtherScalar
    from: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    postCode: AggOtherScalar
    street: AggOtherScalar
    to: AggOtherScalar
    town: AggOtherScalar
}

type AggFloat {
    avg(distinct: Boolean): Float
    count(distinct: Boolean): Int
    "The value of the aggregated field for each group"
    groupValues: [Pair]
    hypi: Hypi
    max: Float
    min: Float
    sum(distinct: Boolean): Float
}

type AggInt {
    avg(distinct: Boolean): Float
    count(distinct: Boolean): Int
    "The value of the aggregated field for each group"
    groupValues: [Pair]
    hypi: Hypi
    max: Int
    min: Int
    sum(distinct: Boolean): Int
}

type AggOtherScalar {
    count(distinct: Boolean): Int
    "The value of the aggregated field for each group"
    groupValues: [Pair]
    hypi: Hypi
}

type AggregatedPolicy implements Policy {
    "defines how the policy arrives at a decision, the options are:"
    decisionStrategy: DecisionStrategy
    hypi: Hypi
    "Positive` or `Negative"
    logic: AuthLogic
    name: String!
    policies(after: String, arcql: String, before: String, first: Int, last: Int): [Policy!]!
}

type AggregatedPolicyAggs {
    decisionStrategy: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    logic: AggOtherScalar
    name: AggOtherScalar
}

"Represents the coordinates for uniquely identifying an addressable app and its release"
type AppId {
    hypi: Hypi
    "The name of the app"
    name: String!
    "The name of the realm"
    realm: String!
    "The release of the app"
    release: String!
}

"""

A client defines an agent that acts on behalf of a user/subject.
Currently implicitly created by Hypi.
"""
type AuthClient {
    hypi: Hypi
    name: String!
    secret: String!
}

type AuthClientAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    name: AggOtherScalar
    secret: AggOtherScalar
}

type BruteForceDetectionOptions {
    "When failure count is reset"
    failureReset: Int
    failureResetUnit: TimeUnit
    hypi: Hypi
    maxLoginFailures: Int!
    "max time a user will be locked out for"
    maxWait: Int
    maxWaitUnit: TimeUnit
    "How long to wait after a quick failure lock out"
    minQuickLoginWait: Int
    minQuickLoginWaitUnit: TimeUnit
    "If login failures occurr too quickly, lock out the user, this sets number of milliseconds that determine \"quickly\""
    quickLoginCheckMillis: Int
    "How long the user ust wait when maxLoginFailures have been reached"
    waitIncrements: Int
    waitIncrementsUnit: TimeUnit
}

type BruteForceDetectionOptionsAggs {
    failureReset: AggInt
    failureResetUnit: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    maxLoginFailures: AggInt
    maxWait: AggInt
    maxWaitUnit: AggOtherScalar
    minQuickLoginWait: AggInt
    minQuickLoginWaitUnit: AggOtherScalar
    quickLoginCheckMillis: AggInt
    waitIncrements: AggInt
    waitIncrementsUnit: AggOtherScalar
}

type ClientPolicy implements Policy {
    clients(after: String, arcql: String, before: String, first: Int, last: Int): [AuthClient!]
    hypi: Hypi
    "Positive` or `Negative"
    logic: AuthLogic
    name: String!
}

type ClientPolicyAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    logic: AggOtherScalar
    name: AggOtherScalar
}

type Coordinate {
    hypi: Hypi
    x: Float!
    y: Float!
}

type CoordinateAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    x: AggFloat
    y: AggFloat
}

type Counter {
    hypi: Hypi
    "A human friendly display label for the counter"
    label: String
    "A name which uniquely identifies this counter in an instance. Must be a letter followed by 0 or more letters, numbers or underscores"
    name: String!
    tags(after: String, arcql: String, before: String, first: Int, last: Int): [String!]
    """

    The value of the counter. Semantically this is intended to be monotonically increasing but this is not currently enforced
    See the Gauge type if you want to arbitrarily increase/decrease/set value on a type
    """
    value: Float!
}

type CounterAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    label: AggOtherScalar
    name: AggOtherScalar
    tags: AggOtherScalar
    value: AggFloat
}

"""

Identifies a given country according to ISO3166
https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes
See also https://www.iso.org/obp/ui/#search and
https://unicode-org.github.io/cldr-staging/charts/37/supplemental/territory_information.html
"""
type Country {
    alpha2code: String
    alpha3code: String
    continent: String
    currencies(after: String, arcql: String, before: String, first: Int, last: Int): [Currency!]
    hypi: Hypi
    internetCCTLD: String
    languagesSpoken(after: String, arcql: String, before: String, first: Int, last: Int): [Language!]
    name: String!
    numericCode: String
    officialLanguage: Language
    sovereignty: String
    stateName: String
    subdivisionCodeLinks: String
}

type CountryAggs {
    alpha2code: AggOtherScalar
    alpha3code: AggOtherScalar
    continent: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    internetCCTLD: AggOtherScalar
    name: AggOtherScalar
    numericCode: AggOtherScalar
    sovereignty: AggOtherScalar
    stateName: AggOtherScalar
    subdivisionCodeLinks: AggOtherScalar
}

type Currency {
    code: String!
    hypi: Hypi
    name: String!
    symbol: String!
}

type CurrencyAggs {
    code: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    name: AggOtherScalar
    symbol: AggOtherScalar
}

type Email {
    hypi: Hypi
    type: String
    value: String!
}

type EmailAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    type: AggOtherScalar
    value: AggOtherScalar
}

"""

Creates a new outbound message.
Note that it automatically send unless the autoSend field is false
https://documentation.Hypi.com/en/latest/api-sending.html#sending
"""
type EmailMessage {
    attachment(after: String, arcql: String, before: String, first: Int, last: Int): [File!]
    bcc(after: String, arcql: String, before: String, first: Int, last: Int): [Email!]
    cc(after: String, arcql: String, before: String, first: Int, last: Int): [Email!]
    """

    Schedule sending in the future
    """
    deliveryTime: DateTime
    from: Email!
    """

    allows to append a custom MIME header to the message (X-My-Header in this case). For example, h:Reply-To to specify Reply-To address.
    """
    headers: Json
    html: String
    hypi: Hypi
    inline(after: String, arcql: String, before: String, first: Int, last: Int): [File!]
    """

    A valid JSON-encoded dictionary, where key is a plain recipient address and value is a dictionary with variables that can be referenced in the message body.
    """
    recipientVariables: Json
    """

    If set to True or yes this requires the message only be sent over a TLS connection. If a TLS connection can not be established, we will not deliver the message.
    If set to False or no, we will still try and upgrade the connection, if that fails the message will be delivered over a plaintext SMTP connection.
    """
    requireTls: Boolean
    responses(after: String, arcql: String, before: String, first: Int, last: Int): [EmailSendingAttempt!]
    """

    If set to True or yes, the certificate and hostname will not be verified when trying to establish a TLS connection and Hypi will accept any certificate during delivery.

    If set to False or no, Hypi will verify the certificate and hostname. If either one can not be verified, a TLS connection will not be established.

    The default is False.
    """
    skipVerification: Boolean
    subject: String!
    tags(after: String, arcql: String, before: String, first: Int, last: Int): [String]
    "Name of the template to use, if present then the given template is used and text/html etc fields in this message are not used"
    template: String
    text: String
    to(after: String, arcql: String, before: String, first: Int, last: Int): [Email!]!
    """

    prefix followed by an arbitrary name allows to attach a custom JSON data to the message. See Attaching Data to Messages for more information.
    """
    variables: Json
}

type EmailMessageAggs {
    bcc_type: AggOtherScalar
    bcc_value: AggOtherScalar
    cc_type: AggOtherScalar
    cc_value: AggOtherScalar
    deliveryTime: AggOtherScalar
    from_type: AggOtherScalar
    from_value: AggOtherScalar
    headers: AggOtherScalar
    html: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    recipientVariables: AggOtherScalar
    requireTls: AggOtherScalar
    skipVerification: AggOtherScalar
    subject: AggOtherScalar
    tags: AggOtherScalar
    template: AggOtherScalar
    text: AggOtherScalar
    to_type: AggOtherScalar
    to_value: AggOtherScalar
    variables: AggOtherScalar
}

type EmailSendingAttempt {
    body: Json
    headers: Json
    hypi: Hypi
    status: EmailEventType
    statusMessage: String
}

type EmailSendingAttemptAggs {
    body: AggOtherScalar
    headers: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    status: AggOtherScalar
    statusMessage: AggOtherScalar
}

"""

Defines a Hypi template that can be parameterised
https://documentation.Hypi.com/en/latest/api-templates.html#store-new-template
"""
type EmailTemplate {
    comment: String
    description: String
    hypi: Hypi
    """

    Name of the template being created. The name can contain alpha-numeric characters, digits and next symbols: .-_~
    """
    name: String
    template: String
}

type EmailTemplateAggs {
    comment: AggOtherScalar
    description: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    name: AggOtherScalar
    template: AggOtherScalar
}

"Email related"
type EmailVerification {
    "The verification code that is included in the email sent. Generated by the server, if provided the provided value is ignored"
    code: String
    "Set by system, cannot be provided"
    confirmed: Boolean
    email: Email!
    "Optionally, the email from which the email will be sent. You MUST have a Hypi email app configured to send from this address"
    from: String
    """

    The HTML contents of the email. This is a Velocity template that will be rendered before being sent.
    The available variables and their types are:
    instance: AppId - You app instance ID
    parent - a map representing the current EmailVerification object
    value - the value of the htmlMessage field
    env: HypiEnv
    """
    htmlMessage: String
    hypi: Hypi
    "Any additional meta data you want to store. For example, you could collect all of the information needed to create the Account"
    meta: Json
    "A plain text version of the email - see this is a velocity template, see htmlMessage for available variables"
    plainTextMessage: String
    "After the link is clicked from the email, redirect the browser to this URL passing a token in the URL i.e. token=jwt.token.here which can be used get the value in the meta field"
    redirectTo: String!
    "Optionally, the subject of the email, this is a velocity template - Hypi provides a default such as \"Please verify your email to <realm>\""
    subject: String
    templateName: String
}

type EmailVerificationAggs {
    code: AggOtherScalar
    confirmed: AggOtherScalar
    email_type: AggOtherScalar
    email_value: AggOtherScalar
    from: AggOtherScalar
    htmlMessage: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    meta: AggOtherScalar
    plainTextMessage: AggOtherScalar
    redirectTo: AggOtherScalar
    subject: AggOtherScalar
    templateName: AggOtherScalar
}

type File {
    children(after: String, arcql: String, before: String, first: Int, last: Int): [File!]
    content: String
    directory: String!
    extension: String
    hypi: Hypi
    isDirectory: Boolean!
    isSharable: Boolean
    isStared: Boolean
    name: String!
    path: String!
    size: Long
    status: FileStatus
    "mime type"
    type: String
    url: URL
}

type FileAggs {
    content: AggOtherScalar
    directory: AggOtherScalar
    extension: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    isDirectory: AggOtherScalar
    isSharable: AggOtherScalar
    isStared: AggOtherScalar
    name: AggOtherScalar
    path: AggOtherScalar
    size: AggOtherScalar
    status: AggOtherScalar
    type: AggOtherScalar
}

"Measures a value at a point in time"
type Gauge {
    hypi: Hypi
    "A human friendly display label for the counter"
    label: String
    "A name which uniquely identifies this counter in an instance. Must be a letter followed by 0 or more letters, numbers or underscores"
    name: String!
    tags(after: String, arcql: String, before: String, first: Int, last: Int): [String!]
    "The current value of this gauge, set, increase or decrease as you see fit"
    value: Float!
}

type GaugeAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    label: AggOtherScalar
    name: AggOtherScalar
    tags: AggOtherScalar
    value: AggFloat
}

type GeoEnvelope {
    hypi: Hypi
    p1: Coordinate!
    p2: Coordinate!
}

type GeoEnvelopeAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
}

"Creates a reference to a GraphQL function in an app instance."
type GraphQLRef {
    field: String!
    hypi: Hypi
    """

    If present this is a set of GraphQL fields that will be selected from the results of the function referenced.
    For example if the type returned by field is "T" and T is the object
    type T {
    a: Int
    b: T2
    }
    type T2 {
    c: String
    }
    then this field can be the selection string:
    a b{c}
    i.e. the GraphQL selection you would use if manually selecting fields from T and T2 WITHOUT any curly braces at the start/end - i.e. no enclosing curlies.
    If not provided, the platform will select hypi{id} meaning the result of this function call will have ONLY the hypi.id field
    """
    selection: String
    type: OpType!
}

type GraphQLRefAggs {
    field: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    selection: AggOtherScalar
    type: AggOtherScalar
}

"Defines a collection for subjects, roles, policies and permissions."
type Group {
    accounts(after: String, arcql: String, before: String, first: Int, last: Int): [Account!]
    children(after: String, arcql: String, before: String, first: Int, last: Int): [Group!]
    hypi: Hypi
    "A unique name identifying this group, implicitly sets the path of the group to /<name> whihc can be referenced in wild card permissions"
    name: String!
    organisations(after: String, arcql: String, before: String, first: Int, last: Int): [Organisation!]
}

type GroupAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    name: AggOtherScalar
}

type GroupPolicy implements Policy {
    groups(after: String, arcql: String, before: String, first: Int, last: Int): [Group!]
    hypi: Hypi
    "Positive` or `Negative"
    logic: AuthLogic
    name: String!
}

type GroupPolicyAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    logic: AggOtherScalar
    name: AggOtherScalar
}

"An object injected into ALL types as the field \"hypi\""
type Hypi {
    "The ISO8601 date of when the object was created"
    created: DateTime
    "The ID of the account which created the object"
    createdBy: ID
    """

    An ID automatically generated by the platform for new objects.
    If provided and the ID does not exist, the provided ID is used instead of a generated one and a new entry is inserted
    If provided and the ID already exists then the existing object is updated.
    """
    id: ID
    """

    When you work with interface fields, Hypi is unable to distinguish which implementation you intend to use
    automatically, you must set this field to the name of the implementation of the interface e.g.
    If creating an AccountPolicy which implements the Policy interface, this field should be set to AccountPolicy
    """
    impl: String
    "The ID of the app instance which created and owns the object"
    instanceId: String
    "The ISO8601 date of when the object was trashed (if it is currently trashed, null otherwise)"
    trashed: DateTime
    "The ISO8601 date of when the object was last modified"
    updated: DateTime
}

"A list of types on which aggregation queries can be executed"
type HypiAggregationType {
    accessToken(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): AccessTokenAggs
    accessTokenWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [AccessTokenGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [AccessTokenAggs]
    account(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): AccountAggs
    accountPolicy(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): AccountPolicyAggs
    accountPolicyWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [AccountPolicyGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [AccountPolicyAggs]
    accountWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [AccountGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [AccountAggs]
    address(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): AddressAggs
    addressWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [AddressGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [AddressAggs]
    aggregatedPolicy(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): AggregatedPolicyAggs
    aggregatedPolicyWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [AggregatedPolicyGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [AggregatedPolicyAggs]
    authClient(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): AuthClientAggs
    authClientWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [AuthClientGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [AuthClientAggs]
    bruteForceDetectionOptions(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): BruteForceDetectionOptionsAggs
    bruteForceDetectionOptionsWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [BruteForceDetectionOptionsGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [BruteForceDetectionOptionsAggs]
    clientPolicy(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): ClientPolicyAggs
    clientPolicyWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [ClientPolicyGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [ClientPolicyAggs]
    coordinate(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): CoordinateAggs
    coordinateWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [CoordinateGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [CoordinateAggs]
    counter(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): CounterAggs
    counterWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [CounterGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [CounterAggs]
    country(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): CountryAggs
    countryWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [CountryGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [CountryAggs]
    currency(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): CurrencyAggs
    currencyWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [CurrencyGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [CurrencyAggs]
    email(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): EmailAggs
    emailMessage(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): EmailMessageAggs
    emailMessageWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [EmailMessageGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [EmailMessageAggs]
    emailSendingAttempt(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): EmailSendingAttemptAggs
    emailSendingAttemptWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [EmailSendingAttemptGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [EmailSendingAttemptAggs]
    emailTemplate(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): EmailTemplateAggs
    emailTemplateWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [EmailTemplateGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [EmailTemplateAggs]
    emailVerification(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): EmailVerificationAggs
    emailVerificationWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [EmailVerificationGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [EmailVerificationAggs]
    emailWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [EmailGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [EmailAggs]
    file(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): FileAggs
    fileWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [FileGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [FileAggs]
    gauge(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): GaugeAggs
    gaugeWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [GaugeGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [GaugeAggs]
    geoEnvelope(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): GeoEnvelopeAggs
    geoEnvelopeWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [GeoEnvelopeGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [GeoEnvelopeAggs]
    graphQLRef(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): GraphQLRefAggs
    graphQLRefWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [GraphQLRefGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [GraphQLRefAggs]
    group(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): GroupAggs
    groupPolicy(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): GroupPolicyAggs
    groupPolicyWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [GroupPolicyGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [GroupPolicyAggs]
    groupWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [GroupGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [GroupAggs]
    image(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): ImageAggs
    imageWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [ImageGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [ImageAggs]
    language(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): LanguageAggs
    languageWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [LanguageGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [LanguageAggs]
    logMessage(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): LogMessageAggs
    logMessageWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [LogMessageGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [LogMessageAggs]
    loginAttempt(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): LoginAttemptAggs
    loginAttemptWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [LoginAttemptGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [LoginAttemptAggs]
    notification(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): NotificationAggs
    notificationCtx(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): NotificationCtxAggs
    notificationCtxWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [NotificationCtxGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [NotificationCtxAggs]
    notificationWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [NotificationGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [NotificationAggs]
    oAuth2AuthorizedClient(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): OAuth2AuthorizedClientAggs
    oAuth2AuthorizedClientWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [OAuth2AuthorizedClientGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [OAuth2AuthorizedClientAggs]
    oAuthProvider(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): OAuthProviderAggs
    oAuthProviderWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [OAuthProviderGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [OAuthProviderAggs]
    organisation(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): OrganisationAggs
    organisationWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [OrganisationGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [OrganisationAggs]
    password(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): PasswordAggs
    passwordReminder(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): PasswordReminderAggs
    passwordReminderWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [PasswordReminderGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [PasswordReminderAggs]
    passwordWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [PasswordGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [PasswordAggs]
    permission(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): PermissionAggs
    permissionWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [PermissionGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [PermissionAggs]
    person(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): PersonAggs
    personName(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): PersonNameAggs
    personNameWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [PersonNameGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [PersonNameAggs]
    personWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [PersonGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [PersonAggs]
    phone(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): PhoneAggs
    phoneWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [PhoneGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [PhoneAggs]
    product(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): ProductAggs
    productWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [ProductGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [ProductAggs]
    realm(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): RealmAggs
    realmLink(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): RealmLinkAggs
    realmLinkWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [RealmLinkGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [RealmLinkAggs]
    realmPolicy(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): RealmPolicyAggs
    realmPolicyWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [RealmPolicyGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [RealmPolicyAggs]
    realmWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [RealmGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [RealmAggs]
    remoteLogin(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): RemoteLoginAggs
    remoteLoginWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [RemoteLoginGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [RemoteLoginAggs]
    requestTemplate(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): RequestTemplateAggs
    requestTemplateWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [RequestTemplateGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [RequestTemplateAggs]
    role(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): RoleAggs
    rolePolicy(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): RolePolicyAggs
    rolePolicyWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [RolePolicyGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [RolePolicyAggs]
    roleWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [RoleGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [RoleAggs]
    script(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): ScriptAggs
    scriptWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [ScriptGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [ScriptAggs]
    serverlessResponse(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): ServerlessResponseAggs
    serverlessResponseWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [ServerlessResponseGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [ServerlessResponseAggs]
    timePolicy(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): TimePolicyAggs
    timePolicyWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [TimePolicyGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [TimePolicyAggs]
    uRL(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): URLAggs
    uRLWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [URLGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [URLAggs]
    video(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): VideoAggs
    videoWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [VideoGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [VideoAggs]
    webhook(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): WebhookAggs
    webhookResponse(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): WebhookResponseAggs
    webhookResponseWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [WebhookResponseGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [WebhookResponseAggs]
    webhookWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [WebhookGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [WebhookAggs]
    workflow(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): WorkflowAggs
    workflowSession(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): WorkflowSessionAggs
    workflowSessionWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [WorkflowSessionGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [WorkflowSessionAggs]
    workflowStep(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): WorkflowStepAggs
    workflowStepData(
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): WorkflowStepDataAggs
    workflowStepDataWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [WorkflowStepDataGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [WorkflowStepDataAggs]
    workflowStepWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [WorkflowStepGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [WorkflowStepAggs]
    workflowWith(
        after: String,
        before: String,
        first: Int,
        "Combines rows into groups based on matching values in specified columns. One row is returned for each group."
        groupBy: [WorkflowGroupByOptions!]!,
        "Filters rows after the results are grouped"
        having: String,
        includeTrashed: Boolean,
        last: Int,
        "Filters rows before the they are summarised into groups by the GROUP BY clause"
        where: String
    ): [WorkflowAggs]
}

"An object available as \"env\" in all scripts"
type HypiEnv {
    apiHost: String
    hypi: Hypi
    websocketHost: String
}

type HypiFilterConnection {
    edges: [HypiResultEdge!]
    hypi: Hypi
    pageInfo: PageInfo!
}

type HypiResultEdge {
    cursor: ID!
    hypi: Hypi
    node: HypiRootAggregate!
}

"A list of types which can be subscribed to"
type HypiSubscriptionUnion {
    AccessToken: AccessToken
    Account: Account
    AccountPolicy: AccountPolicy
    Address: Address
    AggFloat: AggFloat
    AggInt: AggInt
    AggOtherScalar: AggOtherScalar
    AggregatedPolicy: AggregatedPolicy
    AppId: AppId
    AuthClient: AuthClient
    BruteForceDetectionOptions: BruteForceDetectionOptions
    ClientPolicy: ClientPolicy
    Coordinate: Coordinate
    Counter: Counter
    Country: Country
    Currency: Currency
    Email: Email
    EmailMessage: EmailMessage
    EmailSendingAttempt: EmailSendingAttempt
    EmailTemplate: EmailTemplate
    EmailVerification: EmailVerification
    File: File
    Gauge: Gauge
    GeoEnvelope: GeoEnvelope
    GraphQLRef: GraphQLRef
    Group: Group
    GroupPolicy: GroupPolicy
    Hypi: Hypi
    HypiEnv: HypiEnv
    HypiFilterConnection: HypiFilterConnection
    HypiResultEdge: HypiResultEdge
    Image: Image
    Language: Language
    LogMessage: LogMessage
    LoginAttempt: LoginAttempt
    Notification: Notification
    NotificationCtx: NotificationCtx
    OAuth2AuthorizedClient: OAuth2AuthorizedClient
    OAuthProvider: OAuthProvider
    Organisation: Organisation
    PageInfo: PageInfo
    Pair: Pair
    Password: Password
    PasswordReminder: PasswordReminder
    Permission: Permission
    PermissionDescription: PermissionDescription
    Person: Person
    PersonName: PersonName
    Phone: Phone
    Product: Product
    Realm: Realm
    RealmLink: RealmLink
    RealmPolicy: RealmPolicy
    RemoteLogin: RemoteLogin
    RequestTemplate: RequestTemplate
    Role: Role
    RolePolicy: RolePolicy
    Script: Script
    ServerlessResponse: ServerlessResponse
    TimePolicy: TimePolicy
    URL: URL
    Video: Video
    Webhook: Webhook
    WebhookResponse: WebhookResponse
    Workflow: Workflow
    WorkflowSession: WorkflowSession
    WorkflowStep: WorkflowStep
    WorkflowStepData: WorkflowStepData
}

type Image {
    description: String
    file: File!
    hypi: Hypi
    location: Geo
    name: String!
}

type ImageAggs {
    description: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    name: AggOtherScalar
}

"""

==============IaM models==============
union Entity = Account | Organisation #todo unions not yet supported
"""
type Language {
    family: String
    hypi: Hypi
    iso6391Code: String
    iso6392BCode: String
    iso6392TCode: String
    iso6393Code: String
    isoName: String
    nativeName: String
}

type LanguageAggs {
    family: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    iso6391Code: AggOtherScalar
    iso6392BCode: AggOtherScalar
    iso6392TCode: AggOtherScalar
    iso6393Code: AggOtherScalar
    isoName: AggOtherScalar
    nativeName: AggOtherScalar
}

type LogMessage {
    hypi: Hypi
    level: LogLevel!
    message: String
    "Optional, may not be a stacktrace"
    releaseId: String
    stackTrace: String
    "This is optional, we can have system messages that aren't from an app"
    type: String
    "The name of the GraphQL type that the log is for, this is also optional"
    workflow: String
}

type LogMessageAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    level: AggOtherScalar
    message: AggOtherScalar
    releaseId: AggOtherScalar
    stackTrace: AggOtherScalar
    type: AggOtherScalar
    workflow: AggOtherScalar
}

type LoginAttempt {
    errorCode: String
    hypi: Hypi
    successful: Boolean
}

type LoginAttemptAggs {
    errorCode: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    successful: AggOtherScalar
}

type Mutation {
    "Creates a new account which can be used to login and perform various actions in a Realm"
    createAccount(value: AccountInput!): Hypi
    "Used to perform registration of a new realm. Normally only Hypi directly calls this"
    createRealm(value: RealmInput!): Hypi
    "Deletes any objects matching the query up to a maximum of 25 (regardless of the first/last arguments if they are bigger than 25)"
    delete(
        arcql: String!,
        "If true this acts as a 'light' cascade by deleting array references to the matched data.Only array references are deleted, one to one references will remain but will return null. A side effect of this behaviour is that if an object is re-created with the same hypi.id then the one to one references that were not cleared will automatically all point to the new object. This takes precedence over the 'enforceReferentialIntegrityOnDeletes' status set on the instance. Defaults to false"
        clearArrayReferences: Boolean = false,
        type: HypiMutationType!
    ): Int!
    "Deletes the given scalar values from the object with the given ID from the field in the specified type"
    deleteScalars(
        "The query matching the objects to delete the values from"
        arcql: String!,
        "The name of the scalar array field"
        field: String!,
        "The type which contains the field from which you want to delete"
        type: HypiMutationType!,
        "The list of values you want to delete"
        values: [String!]!
    ): Int!
    "Creates a relationship between two existing objects via some field on the source type"
    link(
        andToID: String!,
        from: HypiMutationType!,
        "The instance ID in which the from ID exists, defaults to this instance"
        fromInstanceId: String,
        to: HypiMutationType!,
        "The instance ID in which the to ID exists, defaults to this instance"
        toInstanceId: String,
        via: String!,
        whereFromID: String!
    ): Boolean!
    math(values: HypiMathType): [Hypi!]!
    "Marks any object that matches the filter as trash. Those objects will not be returned in get or find queries unless they're marked as not trash later. Maximum of 25 will be trashed (regardless of the first/last arguments if they are bigger than 25)"
    trash(arcql: String!, type: HypiMutationType!): Int!
    "Removes the link between two objects WITHOUT deleting either object"
    unlink(
        andToID: String!,
        from: HypiMutationType!,
        "The instance ID in which the from ID exists, defaults to this instance"
        fromInstanceId: String,
        to: HypiMutationType!,
        "The instance ID in which the to ID exists, defaults to this instance"
        toInstanceId: String,
        via: String!,
        whereFromID: String!
    ): Boolean!
    "Marks any object that matches the filter as NOT trash if they were previous trashed with the 'trash' function"
    untrash(arcql: String!, type: HypiMutationType!): Int!
    "Inserts or updates a set of values. To update an existing value provide the hypi.id"
    upsert(values: HypiUpsertInputUnion!): [Hypi!]!
}

"Events that can be raised by the system to inform you about errors or other state that happened asynchronously, hence you may not otherwise have been told this info."
type Notification {
    ctx: NotificationCtx
    hypi: Hypi
    message: String
}

type NotificationAggs {
    ctx_targetAccount: AggOtherScalar
    ctx_type: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    message: AggOtherScalar
}

type NotificationCtx {
    hypi: Hypi
    targetAccount: ID
    "The type that the notification applies to"
    type: String
}

type NotificationCtxAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    targetAccount: AggOtherScalar
    type: AggOtherScalar
}

type OAuth2AuthorizedClient {
    accessToken: String
    clientRegistrationId: String
    hypi: Hypi
    principalName: String
    refreshToken: String
}

type OAuth2AuthorizedClientAggs {
    accessToken: AggOtherScalar
    clientRegistrationId: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    principalName: AggOtherScalar
    refreshToken: AggOtherScalar
}

type OAuthProvider {
    authorizationGrantType: AuthorizationGrantType
    authorizationUri: String
    clientAuthenticationMethod: ClientAuthenticationMethod
    " instanceId-(hypi.id = registrationId)"
    clientId: String!
    clientName: String
    clientSecret: String!
    configurationMetadata(after: String, arcql: String, before: String, first: Int, last: Int): [Pair!]
    hypi: Hypi
    hypiFailureRedirectUri: String
    hypiSuccessRedirectUri: String
    jwkSetUri: String
    redirectUriTemplate: String
    scopes(after: String, arcql: String, before: String, first: Int, last: Int): [String!]
    tokenUri: String
    userInfoAuthenticationMethod: AuthenticationMethod
    userInfoUri: String
    userNameAttributeName: UserNameAttributeName
}

type OAuthProviderAggs {
    authorizationGrantType: AggOtherScalar
    authorizationUri: AggOtherScalar
    clientAuthenticationMethod: AggOtherScalar
    clientId: AggOtherScalar
    clientName: AggOtherScalar
    clientSecret: AggOtherScalar
    hypiFailureRedirectUri: AggOtherScalar
    hypiSuccessRedirectUri: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    jwkSetUri: AggOtherScalar
    redirectUriTemplate: AggOtherScalar
    scopes: AggOtherScalar
    tokenUri: AggOtherScalar
    userInfoAuthenticationMethod: AggOtherScalar
    userInfoUri: AggOtherScalar
    userNameAttributeName: AggOtherScalar
}

"Used to represent arbitrary customer specific collections of entities e.g. an Organisation, a Meetup or Friends"
type Organisation {
    addresses(after: String, arcql: String, before: String, first: Int, last: Int): [Address!]
    emails(after: String, arcql: String, before: String, first: Int, last: Int): [Email!]
    hypi: Hypi
    incorporated: DateTime
    logo: Image
    members(after: String, arcql: String, before: String, first: Int, last: Int): [Account!]
    name: String!
    phones(after: String, arcql: String, before: String, first: Int, last: Int): [Phone!]
    subsidiaries(after: String, arcql: String, before: String, first: Int, last: Int): [Organisation!]
}

type OrganisationAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    incorporated: AggOtherScalar
    name: AggOtherScalar
}

"See https://relay.dev/graphql/connections.htm#sec-undefined.PageInfo"
type PageInfo {
    "relay modern - https://relay.dev/graphql/connections.htm#note-95f8a"
    endCursor: ID!
    hasNextPage: Boolean!
    hasPreviousPage: Boolean!
    hypi: Hypi
    "If present, contains the pagination cursors that can be used to get the next N pages"
    nextOffsets: [String!]
    """

    relay modern
    If present, is the page size that is used to generate the previousOffsets and nextOffsets if they're present
    """
    pageLimit: Int
    "If present, contains the pagination cursors that can be used to get the previous N pages"
    previousOffsets: [String!]
    startCursor: ID!
}

type Pair {
    hypi: Hypi
    key: String
    value: String
}

type Password {
    expired: Boolean
    hypi: Hypi
    """

    password is never returned
    further, the @secret directive enforces this, queries can be use to perform comparison against the field but it is never returned
    """
    value: String!
}

type PasswordAggs {
    expired: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    value: AggOtherScalar
}

"""

To reset an Account's password, create a `PasswordReminder`.

This will generate a code in the `code` field that can be referenced using $!{parent.code} in the `htmlMessage` or `plainTextMessage` fields.

This will send an email to the email in the `to` field. In the message you should provide a link to a URL where the user can enter their new password.
Include the code in this URL e.g. https://my-app.com/reset-password?code=$!{parent.code}.

When the user gets to this page, you will have the password reset code in the URL query string. Get this code from the URL
and when the user enter their new password, make a POST request to the Hypi API e.g.
POST <hypi-domain>/email/reset/<domain> - where <domain> is app instance domain.

In the body of the request send a JSON like this:
{"code": "<the-code-from-the-URL>", "password": "<the-user's-new-password>"}

Hypi will change the user's password and return HTTP status 200.
"""
type PasswordReminder {
    "The verification code that is included in the email sent. Generated by the server, if provided the provided value is ignored"
    code: String
    "Optionally, the email from which the email will be sent. You MUST have a Hypi email app configured to send from this address"
    from: String
    """

    The HTML contents of the email. This is a Velocity template that will be rendered before being sent.
    The available variables and their types are:
    instance: AppId - You app instance ID
    parent - a map representing the current EmailVerification object
    value - the value of the htmlMessage field
    env: HypiEnv
    """
    htmlMessage: String
    hypi: Hypi
    "A plain text version of the email - see this is a velocity template, see htmlMessage for available variables"
    plainTextMessage: String
    "Optionally, the subject of the email, this is a velocity template - Hypi provides a default such as \"Please verify your email to <realm>\""
    subject: String
    "The Account email that needs to be changed"
    to: Email!
    "If true the reset code has not yet been used."
    valid: Boolean
}

type PasswordReminderAggs {
    code: AggOtherScalar
    from: AggOtherScalar
    htmlMessage: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    plainTextMessage: AggOtherScalar
    subject: AggOtherScalar
    to_type: AggOtherScalar
    to_value: AggOtherScalar
    valid: AggOtherScalar
}

type Permission {
    "defines how the policy arrives at a decision, defaults to Unanimous"
    decisionStrategy: DecisionStrategy
    hypi: Hypi
    "If true, this permission grants/denies access to all accounts (including anonymous account)"
    includeAllAccounts: Boolean
    name: String!
    "Query, Mutation or Subscription"
    operationType: OpType!
    operations(after: String, arcql: String, before: String, first: Int, last: Int): [String]!
    policies(after: String, arcql: String, before: String, first: Int, last: Int): [Policy!]
    """

    If present then the scopes in this permission will have the given policies applied to this resource.
    This can be used for example to prevent mutation on a resource by a user, group etc
    """
    resource: String
    scopes(after: String, arcql: String, before: String, first: Int, last: Int): [String!]!
    """

    When a Permission is created, the instance to which it grants access is assumed to be the same as the one in which it is created.
    This means - if this field is not provided, it will be set to the current instance by default.
    Some times, it is necessary to grant permission to a resource that exists in a different instance.
    In those cases, this field can be set to the instance ID from which the resource needs to be accessed.
    It is also possible to set this to the wildcard character '*' - in which case, this permission grants access to the resource from any instance.
    Note that wildcard can only be used to grant access, by default, access is denied to all other instances
    so a negative policy will have no effect when this field is set to '*'.
    """
    targetInstance: String
    "The type that this permission applies to"
    type: String!
}

type PermissionAggs {
    decisionStrategy: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    includeAllAccounts: AggOtherScalar
    name: AggOtherScalar
    operationType: AggOtherScalar
    operations: AggOtherScalar
    resource: AggOtherScalar
    scopes: AggOtherScalar
    targetInstance: AggOtherScalar
    type: AggOtherScalar
}

type PermissionDescription {
    groups: [Group!]
    hypi: Hypi
    organisations: [Organisation!]
    permissions(after: String, limit: Int = 25, resources: [String!], type: String): [Permission]
    realms: [Realm!]
    roles: [Role!]
}

type Person {
    addresses(after: String, arcql: String, before: String, first: Int, last: Int): [Address!]
    avatar: Image
    dob: DateTime
    gender: Gender
    hypi: Hypi
    names(after: String, arcql: String, before: String, first: Int, last: Int): [PersonName!]!
    phones(after: String, arcql: String, before: String, first: Int, last: Int): [Phone!]
    preferences(after: String, arcql: String, before: String, first: Int, last: Int): [Pair!]
    roles(after: String, arcql: String, before: String, first: Int, last: Int): [Pair!]
}

type PersonAggs {
    dob: AggOtherScalar
    gender: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
}

type PersonName {
    firstName: String
    from: DateTime
    hypi: Hypi
    lastName: String
    title: String
    to: DateTime
}

type PersonNameAggs {
    firstName: AggOtherScalar
    from: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    lastName: AggOtherScalar
    title: AggOtherScalar
    to: AggOtherScalar
}

type Phone {
    code: String
    country: Country
    hypi: Hypi
    number: String!
}

type PhoneAggs {
    code: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    number: AggOtherScalar
}

type Product {
    description: String!
    hypi: Hypi
    price: Float
    title: String!
}

type ProductAggs {
    description: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    price: AggFloat
    title: AggOtherScalar
}

type Query {
    aggregate: HypiAggregationType
    "Find objects of the given type which match the query. Use a conditional fragment to select fields as in https://graphql.org/learn/schema/#union-types"
    find(after: String, arcql: String!, before: String, first: Int, includeTrashed: Boolean, last: Int, type: HypiMutationType!): HypiFilterConnection!
    "Gets a single object by its ID (hypi.id)"
    get(id: String!, type: HypiMutationType!): HypiRootAggregate
    hasPermission(req: [PermissionRequest!]!): [Boolean]
    login(password: String!, username: String!): AccessToken
    loginByEmail(email: String!, password: String!): AccessToken
    me: PermissionDescription
}

" namespace for containing authz objects and their relationships."
type Realm {
    "If true users can register without an admin creating their account"
    allowRegistrations: Boolean
    "Optionally defines some options to help detect and protect against brute force login attempts"
    bruteForceDetection: BruteForceDetectionOptions
    "The name displayed in the user interface"
    displayName: String
    hypi: Hypi
    logo: Image
    """

    the name identifying the organisation and becomes the URL by which it is accessed e.g. alpha-corp.hypi.app, where alpha-corp is name
    If not provided one will be automatically generated
    """
    name: String
    organisations(after: String, arcql: String, before: String, first: Int, last: Int): [Organisation!]!
    referrer: String
    remoteLoginId: String
    "if true users must verify their email before they're allowed to login"
    verifyEmail: Boolean
}

type RealmAggs {
    allowRegistrations: AggOtherScalar
    displayName: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    name: AggOtherScalar
    referrer: AggOtherScalar
    remoteLoginId: AggOtherScalar
    verifyEmail: AggOtherScalar
}

type RealmLink {
    accounts(after: String, arcql: String, before: String, first: Int, last: Int): [Account!]!
    hypi: Hypi
    name: String!
}

type RealmLinkAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    name: AggOtherScalar
}

type RealmPolicy implements Policy {
    hypi: Hypi
    "Positive` or `Negative"
    logic: AuthLogic
    name: String!
    realms(after: String, arcql: String, before: String, first: Int, last: Int): [RealmLink!]
}

type RealmPolicyAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    logic: AggOtherScalar
    name: AggOtherScalar
}

type RemoteLogin {
    email: String
    hypi: Hypi
    otherAttributes: Json
    remoteId: String
    type: String
}

type RemoteLoginAggs {
    email: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    otherAttributes: AggOtherScalar
    remoteId: AggOtherScalar
    type: AggOtherScalar
}

"Defines the templates that should be applied to a given HTTP request"
type RequestTemplate {
    hypi: Hypi
    name: String!
    request: String
    response: String
}

type RequestTemplateAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    name: AggOtherScalar
    request: AggOtherScalar
    response: AggOtherScalar
}

type Role {
    accounts(after: String, arcql: String, before: String, first: Int, last: Int): [Account!]
    hypi: Hypi
    name: String!
}

type RoleAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    name: AggOtherScalar
}

type RolePolicy implements Policy {
    hypi: Hypi
    "Positive` or `Negative"
    logic: AuthLogic
    name: String!
    roles(after: String, arcql: String, before: String, first: Int, last: Int): [Role!]!
}

type RolePolicyAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    logic: AggOtherScalar
    name: AggOtherScalar
}

type Script {
    body: String!
    hypi: Hypi
    name: String!
    type: TanType!
}

type ScriptAggs {
    body: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    name: AggOtherScalar
    type: AggOtherScalar
}

type ServerlessResponse {
    attributes(after: String, arcql: String, before: String, first: Int, last: Int): [String]
    body: Json
    chunked: Boolean
    cookies: Json
    files(after: String, arcql: String, before: String, first: Int, last: Int): [File]
    headers: Json
    hypi: Hypi
    method: String
    multiPart: Boolean
    path: String
    queryString: Json
}

type ServerlessResponseAggs {
    attributes: AggOtherScalar
    body: AggOtherScalar
    chunked: AggOtherScalar
    cookies: AggOtherScalar
    headers: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    method: AggOtherScalar
    multiPart: AggOtherScalar
    path: AggOtherScalar
    queryString: AggOtherScalar
}

type Subscription {
    "Subscribe to mutations on the given type."
    subscribe(id: String): HypiSubscriptionUnion!
}

type TimePolicy implements Policy {
    accounts(after: String, arcql: String, before: String, first: Int, last: Int): [Account!]
    clients(after: String, arcql: String, before: String, first: Int, last: Int): [AuthClient!]
    "(yyyy-MM-dd hh:mm:ss) can be used for example to ensure a file is not viewable before the given date"
    from: DateTime
    groups(after: String, arcql: String, before: String, first: Int, last: Int): [Group!]
    hypi: Hypi
    "Positive` or `Negative"
    logic: AuthLogic
    name: String!
    realms(after: String, arcql: String, before: String, first: Int, last: Int): [RealmLink!]
    roles(after: String, arcql: String, before: String, first: Int, last: Int): [Role!]
    "can be used to ensure a file is not viewable after a given date"
    to: DateTime
}

type TimePolicyAggs {
    from: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    logic: AggOtherScalar
    name: AggOtherScalar
    to: AggOtherScalar
}

type URL {
    host: String
    hypi: Hypi
    path: String!
    port: Int
    queryParams: Json
}

type URLAggs {
    host: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    path: AggOtherScalar
    port: AggInt
    queryParams: AggOtherScalar
}

type Video {
    description: String
    file: File!
    hypi: Hypi
    location: Geo
    name: String!
    thumbnails(after: String, arcql: String, before: String, first: Int, last: Int): [Image!]
}

type VideoAggs {
    description: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    name: AggOtherScalar
}

"""

Defines a web hook that can be used to trigger Hypi GraphQL functions on a given app.
The account specified in the web hook must have access to the app/instance and must be authorised to call the functions specified.
"""
type Webhook {
    """

    Defaults to the account creating the Webhook.
    Hypi will generate an authorisation token automatically for the account when the web hook is triggered.
    This token will then be used to execute the triggers in the web hook (query or mutation).
    For security an account should be created specifically for invoking web hooks and an AccountPolicy should be created that grants access only to the specified functions or otherwise limit the scope of what the account can do.
    """
    as: Account
    hypi: Hypi
    "The name by which this web hook is referenced in the URL, if missing the webhook is only adressable by ID"
    name: String
    """

    This refers to a GraphQL function.
    The function must have a graphql argument defined as `(payload: WebhookPayload): WebhookPayload`
    The function can trigger a workflow or operate on the payload itself.
    """
    query: GraphQLRef!
}

type WebhookAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    name: AggOtherScalar
    query_field: AggOtherScalar
    query_selection: AggOtherScalar
    query_type: AggOtherScalar
}

"""

If the query or mutation functions in the Webhook definition returns this then it controls what the server responds with
For example, the GraphQL function can return a 301 or 302 status and a Location header to an external URL to cause a redirect.
"""
type WebhookResponse {
    body: Json
    headers: Json
    hypi: Hypi
    status: Int
}

type WebhookResponseAggs {
    body: AggOtherScalar
    headers: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    status: AggInt
}

"""

A workflow defines a sequence of steps that execute in a defined order (you set the order field on each step).
It is one way in which Hypi allows you to do composition, so similarities can be drawn to function composition with some specifics thrown in for Hypi and GraphQL.

If two steps have the same order their execution order is undefined with relation to each other.
Every step has a GraphQL function that is executed for that step.

When a Workflow is executed it creates a WorkflowSession. The result of each step in the workflow is added to the session.

The first step can have any parameters you want. For the other steps there are some rules that define how the system maps
parameters to the function in these steps. These rules are:

1. Any step (including the first step) can have a parameter "params: Json" i.e. name = params and type is Json.
This params is a map of the arguments passed to the first function in the Workflow. For example if the function was defined as
step1(a: Int, b: Json, c: MyType): T
in this case the "params" Json object would be have the fields a, b and c set to the values the function was executed with.
Normally, this is used in the first step but can be used in any step that wants access to this data.

2. Any step can have a parameter "session: WorkflowSession" - this is the current workflow's session and contains the results of all steps before the current one.
You can identify the results for a specific step by finding the result using the step's name in the session's data array.

3. Except the first step, a parameter "previous: T" where T is the result type of the previous step can be used.
In this case, the platform will use the output of the previous function for this parameter.
Note that if the type is not the same as the last step's output type then the workflow will fail if the field is not optional.
If the field is optional then the platform will not provide it and it would therefore be null if you try to use it.

4. Except the first step, pass-through is possible. This is where the parameters from the first step are passed through
to other steps by name and type. i.e. given
step1(a: Int, b: String): String
step2(a: Int): ID
In this case, the variable "a" in both step1 and step2 will have the same value that step1 was executed with.
Incidentally, this is the same as getting "a" from the "params" Json.
"""
type Workflow implements WorkflowAsync & WorkflowConditional & WorkflowExecutableAs & WorkflowParallel & WorkflowRepeatable & WorkflowTimed {
    async: Boolean
    """

    If present, this is a cron schedule to automatically execute this Workflow
    The syntax as defined at https://www.manpagez.com/man/5/crontab/
    NOTE: The special strings @hourly, @daily etc are NOT supported
    """
    cronSchedule: String
    evaluateIf: GraphQLRef
    """

    An ArcQL query to find the account e.g. hypi.id = 'user123' to find by id or username = 'blah' to find by username
    If present, execution of the steps in the Workflow will be done as this account
    If not specified, it defaults to the account making the request
    """
    execAs: String
    hypi: Hypi
    """

    Specifies the the max time an async task should be allowed to execute. When this time has elapsed the task will be killed.
    The format is ISO8601 durations https://en.wikipedia.org/wiki/ISO_8601#Durations
    e.g. P1M is 1 month and PT1M is 1 minute
    """
    maxExecutionTime: String
    name: String!
    "If present AND true, all steps in this block are executed at the same time."
    parallel: Boolean
    repeatIf: GraphQLRef
    repeatN: Int
    steps(after: String, arcql: String, before: String, first: Int, last: Int): [WorkflowStep!]
}

type WorkflowAggs {
    async: AggOtherScalar
    cronSchedule: AggOtherScalar
    evaluateIf_field: AggOtherScalar
    evaluateIf_selection: AggOtherScalar
    evaluateIf_type: AggOtherScalar
    execAs: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    maxExecutionTime: AggOtherScalar
    name: AggOtherScalar
    parallel: AggOtherScalar
    repeatIf_field: AggOtherScalar
    repeatIf_selection: AggOtherScalar
    repeatIf_type: AggOtherScalar
    repeatN: AggInt
}

type WorkflowSession {
    data(after: String, arcql: String, before: String, first: Int, last: Int): [WorkflowStepData!]
    hypi: Hypi
}

type WorkflowSessionAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
}

type WorkflowStep implements WorkflowAsync & WorkflowConditional & WorkflowExecutableAs & WorkflowOrdered & WorkflowRepeatable & WorkflowTimed {
    async: Boolean
    evaluateIf: GraphQLRef
    """

    An ArcQL query to find the account e.g. hypi.id = 'user123' to find by id or username = 'blah' to find by username
    If present, execution of the steps in the Workflow will be done as this account
    If not specified, it defaults to the account making the request
    """
    execAs: String
    "The function to execute for this step, the data returned by the step can subsequently be used in other steps"
    fn: GraphQLRef!
    hypi: Hypi
    """

    Specifies the the max time an async task should be allowed to execute. When this time has elapsed the task will be killed.
    The format is ISO8601 durations https://en.wikipedia.org/wiki/ISO_8601#Durations
    e.g. P1M is 1 month and PT1M is 1 minute
    """
    maxExecutionTime: String
    "A name that can be used to reference or trigger this step"
    name: String
    order: Int!
    repeatIf: GraphQLRef
    repeatN: Int
}

type WorkflowStepAggs {
    async: AggOtherScalar
    evaluateIf_field: AggOtherScalar
    evaluateIf_selection: AggOtherScalar
    evaluateIf_type: AggOtherScalar
    execAs: AggOtherScalar
    fn_field: AggOtherScalar
    fn_selection: AggOtherScalar
    fn_type: AggOtherScalar
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    maxExecutionTime: AggOtherScalar
    name: AggOtherScalar
    order: AggInt
    repeatIf_field: AggOtherScalar
    repeatIf_selection: AggOtherScalar
    repeatIf_type: AggOtherScalar
    repeatN: AggInt
}

type WorkflowStepData {
    hypi: Hypi
    stepName: String!
    stepResult: Any!
}

type WorkflowStepDataAggs {
    hypi_created: AggOtherScalar
    hypi_createdBy: AggOtherScalar
    hypi_id: AggOtherScalar
    hypi_impl: AggOtherScalar
    hypi_instanceId: AggOtherScalar
    hypi_trashed: AggOtherScalar
    hypi_updated: AggOtherScalar
    stepName: AggOtherScalar
    stepResult: AggOtherScalar
}

"All fields defined by AccessToken"
enum AccessTokenFields {
    errorCode
    errorMsg
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    sessionExpires
    sessionToken
}

"Scalar fields defined by AccessToken"
enum AccessTokenScalarFields {
    errorCode
    errorMsg
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    sessionExpires
    sessionToken
}

"All fields defined by Account"
enum AccountFields {
    attempts
    emails
    enabled
    groups
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    owner
    password
    phones
    remoteLogins
    roles
    username
    verified
}

"All fields defined by AccountPolicy"
enum AccountPolicyFields {
    accounts
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "Positive` or `Negative"
    logic
    name
}

"Scalar fields defined by AccountPolicy"
enum AccountPolicyScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "Positive` or `Negative"
    logic
    name
}

"Scalar fields defined by Account"
enum AccountScalarFields {
    enabled
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    username
    verified
}

"All fields defined by Address"
enum AddressFields {
    city
    country
    county
    door
    "  country: Country"
    from
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    postCode
    street
    to
    town
}

"Scalar fields defined by Address"
enum AddressScalarFields {
    city
    county
    door
    "  country: Country"
    from
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    postCode
    street
    to
    town
}

"All fields defined by AggFloat"
enum AggFloatFields {
    avg
    count
    "The value of the aggregated field for each group"
    groupValues
    "The value of the aggregated field for each group"
    groupValues_hypi
    "The value of the aggregated field for each group"
    groupValues_key
    "The value of the aggregated field for each group"
    groupValues_value
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    max
    min
    sum
}

"Scalar fields defined by AggFloat"
enum AggFloatScalarFields {
    avg
    count
    "The value of the aggregated field for each group"
    groupValues_key
    "The value of the aggregated field for each group"
    groupValues_value
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    max
    min
    sum
}

"All fields defined by AggInt"
enum AggIntFields {
    avg
    count
    "The value of the aggregated field for each group"
    groupValues
    "The value of the aggregated field for each group"
    groupValues_hypi
    "The value of the aggregated field for each group"
    groupValues_key
    "The value of the aggregated field for each group"
    groupValues_value
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    max
    min
    sum
}

"Scalar fields defined by AggInt"
enum AggIntScalarFields {
    avg
    count
    "The value of the aggregated field for each group"
    groupValues_key
    "The value of the aggregated field for each group"
    groupValues_value
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    max
    min
    sum
}

enum AggOrder {
    ASC
    DESC
}

"All fields defined by AggOtherScalar"
enum AggOtherScalarFields {
    count
    "The value of the aggregated field for each group"
    groupValues
    "The value of the aggregated field for each group"
    groupValues_hypi
    "The value of the aggregated field for each group"
    groupValues_key
    "The value of the aggregated field for each group"
    groupValues_value
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
}

"Scalar fields defined by AggOtherScalar"
enum AggOtherScalarScalarFields {
    count
    "The value of the aggregated field for each group"
    groupValues_key
    "The value of the aggregated field for each group"
    groupValues_value
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
}

"All fields defined by AggregatedPolicy"
enum AggregatedPolicyFields {
    "defines how the policy arrives at a decision, the options are:"
    decisionStrategy
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "Positive` or `Negative"
    logic
    name
    policies
}

"Scalar fields defined by AggregatedPolicy"
enum AggregatedPolicyScalarFields {
    "defines how the policy arrives at a decision, the options are:"
    decisionStrategy
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "Positive` or `Negative"
    logic
    name
}

"All fields defined by AppId"
enum AppIdFields {
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "The name of the app"
    name
    "The name of the realm"
    realm
    "The release of the app"
    release
}

"Scalar fields defined by AppId"
enum AppIdScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "The name of the app"
    name
    "The name of the realm"
    realm
    "The release of the app"
    release
}

"All fields defined by AuthClient"
enum AuthClientFields {
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    name
    secret
}

"Scalar fields defined by AuthClient"
enum AuthClientScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    name
    secret
}

enum AuthLogic {
    "Access will be denied"
    Negative
    "Access will be granted"
    Positive
}

enum AuthenticationMethod {
    form
    header
    query
}

enum AuthorizationGrantType {
    authorization_code
    client_credentials
    implicit
    refresh_token
}

"All fields defined by BruteForceDetectionOptions"
enum BruteForceDetectionOptionsFields {
    "When failure count is reset"
    failureReset
    failureResetUnit
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    maxLoginFailures
    "max time a user will be locked out for"
    maxWait
    maxWaitUnit
    "How long to wait after a quick failure lock out"
    minQuickLoginWait
    minQuickLoginWaitUnit
    "If login failures occurr too quickly, lock out the user, this sets number of milliseconds that determine \"quickly\""
    quickLoginCheckMillis
    "How long the user ust wait when maxLoginFailures have been reached"
    waitIncrements
    waitIncrementsUnit
}

"All numeric fields defined by BruteForceDetectionOptions"
enum BruteForceDetectionOptionsNumericFields {
    failureReset
    maxLoginFailures
    maxWait
    minQuickLoginWait
    quickLoginCheckMillis
    waitIncrements
}

"Scalar fields defined by BruteForceDetectionOptions"
enum BruteForceDetectionOptionsScalarFields {
    "When failure count is reset"
    failureReset
    failureResetUnit
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    maxLoginFailures
    "max time a user will be locked out for"
    maxWait
    maxWaitUnit
    "How long to wait after a quick failure lock out"
    minQuickLoginWait
    minQuickLoginWaitUnit
    "If login failures occurr too quickly, lock out the user, this sets number of milliseconds that determine \"quickly\""
    quickLoginCheckMillis
    "How long the user ust wait when maxLoginFailures have been reached"
    waitIncrements
    waitIncrementsUnit
}

enum ClientAuthenticationMethod {
    basic
    post
}

"All fields defined by ClientPolicy"
enum ClientPolicyFields {
    clients
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "Positive` or `Negative"
    logic
    name
}

"Scalar fields defined by ClientPolicy"
enum ClientPolicyScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "Positive` or `Negative"
    logic
    name
}

"""

input ComputedAggField {
field: String! #The name of the field in the GraphQL type
projectTo: String #The name of the field that should receive the aggregated value - if null, the value is projected to the same field IFF the type is Int or Float
agg: ComputedAggType #Defaults to COUNT
}
"""
enum ComputedAggType {
    AVG
    COUNT
    MAX
    MIN
    SUM
}

"All fields defined by Coordinate"
enum CoordinateFields {
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    x
    y
}

"All numeric fields defined by Coordinate"
enum CoordinateNumericFields {
    x
    y
}

"Scalar fields defined by Coordinate"
enum CoordinateScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    x
    y
}

"All fields defined by Counter"
enum CounterFields {
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "A human friendly display label for the counter"
    label
    "A name which uniquely identifies this counter in an instance. Must be a letter followed by 0 or more letters, numbers or underscores"
    name
    tags
    """

    The value of the counter. Semantically this is intended to be monotonically increasing but this is not currently enforced
    See the Gauge type if you want to arbitrarily increase/decrease/set value on a type
    """
    value
}

"All numeric fields defined by Counter"
enum CounterNumericFields {
    value
}

"Scalar fields defined by Counter"
enum CounterScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "A human friendly display label for the counter"
    label
    "A name which uniquely identifies this counter in an instance. Must be a letter followed by 0 or more letters, numbers or underscores"
    name
    tags
    """

    The value of the counter. Semantically this is intended to be monotonically increasing but this is not currently enforced
    See the Gauge type if you want to arbitrarily increase/decrease/set value on a type
    """
    value
}

"All fields defined by Country"
enum CountryFields {
    alpha2code
    alpha3code
    continent
    currencies
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    internetCCTLD
    languagesSpoken
    name
    numericCode
    officialLanguage
    sovereignty
    stateName
    subdivisionCodeLinks
}

"Scalar fields defined by Country"
enum CountryScalarFields {
    alpha2code
    alpha3code
    continent
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    internetCCTLD
    name
    numericCode
    sovereignty
    stateName
    subdivisionCodeLinks
}

"All fields defined by Currency"
enum CurrencyFields {
    code
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    name
    symbol
}

"Scalar fields defined by Currency"
enum CurrencyScalarFields {
    code
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    name
    symbol
}

"""

The decision strategy dictates how the policies associated with a given permission are evaluated and how a final decision is obtained.
'Affirmative' means that at least one policy must evaluate to a positive decision in order for the final decision to be also positive.
'Unanimous' means that all policies must evaluate to a positive decision in order for the final decision to be also positive.
'Consensus' means that the number of positive decisions must be greater than the number of negative decisions.
If the number of positive and negative is the same, the final decision will be negative.
"""
enum DecisionStrategy {
    "at least one policy listed must be positive for this policy to result in a positive decision"
    Affirmative
    "The number of policies that are positive must be greater than those that are negative e.g. if 5 policies are included, at least 3 must be positive for this policy to be positive"
    Consensus
    "There MUST be at least one policy AND all policies listed must be positive for this policy to result in a positive decision"
    Unanimous
}

"The event field of HypiEvent will be one of these"
enum EmailEventType {
    "Hypi sent the email and it was accepted by the recipient email server."
    delivered
    """

    Hypi could not deliver the email to the recipient email server.
    """
    failed
}

"All fields defined by Email"
enum EmailFields {
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    type
    value
}

"All fields defined by EmailMessage"
enum EmailMessageFields {
    attachment
    bcc
    bcc_hypi
    bcc_type
    bcc_value
    cc
    cc_hypi
    cc_type
    cc_value
    """

    Schedule sending in the future
    """
    deliveryTime
    from
    from_hypi
    from_type
    from_value
    """

    allows to append a custom MIME header to the message (X-My-Header in this case). For example, h:Reply-To to specify Reply-To address.
    """
    headers
    html
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    inline
    """

    A valid JSON-encoded dictionary, where key is a plain recipient address and value is a dictionary with variables that can be referenced in the message body.
    """
    recipientVariables
    """

    If set to True or yes this requires the message only be sent over a TLS connection. If a TLS connection can not be established, we will not deliver the message.
    If set to False or no, we will still try and upgrade the connection, if that fails the message will be delivered over a plaintext SMTP connection.
    """
    requireTls
    responses
    """

    If set to True or yes, the certificate and hostname will not be verified when trying to establish a TLS connection and Hypi will accept any certificate during delivery.

    If set to False or no, Hypi will verify the certificate and hostname. If either one can not be verified, a TLS connection will not be established.

    The default is False.
    """
    skipVerification
    subject
    tags
    "Name of the template to use, if present then the given template is used and text/html etc fields in this message are not used"
    template
    text
    to
    to_hypi
    to_type
    to_value
    """

    prefix followed by an arbitrary name allows to attach a custom JSON data to the message. See Attaching Data to Messages for more information.
    """
    variables
}

"Scalar fields defined by EmailMessage"
enum EmailMessageScalarFields {
    bcc_type
    bcc_value
    cc_type
    cc_value
    """

    Schedule sending in the future
    """
    deliveryTime
    from_type
    from_value
    """

    allows to append a custom MIME header to the message (X-My-Header in this case). For example, h:Reply-To to specify Reply-To address.
    """
    headers
    html
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    """

    A valid JSON-encoded dictionary, where key is a plain recipient address and value is a dictionary with variables that can be referenced in the message body.
    """
    recipientVariables
    """

    If set to True or yes this requires the message only be sent over a TLS connection. If a TLS connection can not be established, we will not deliver the message.
    If set to False or no, we will still try and upgrade the connection, if that fails the message will be delivered over a plaintext SMTP connection.
    """
    requireTls
    """

    If set to True or yes, the certificate and hostname will not be verified when trying to establish a TLS connection and Hypi will accept any certificate during delivery.

    If set to False or no, Hypi will verify the certificate and hostname. If either one can not be verified, a TLS connection will not be established.

    The default is False.
    """
    skipVerification
    subject
    tags
    "Name of the template to use, if present then the given template is used and text/html etc fields in this message are not used"
    template
    text
    to_type
    to_value
    """

    prefix followed by an arbitrary name allows to attach a custom JSON data to the message. See Attaching Data to Messages for more information.
    """
    variables
}

"Scalar fields defined by Email"
enum EmailScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    type
    value
}

"All fields defined by EmailSendingAttempt"
enum EmailSendingAttemptFields {
    body
    headers
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    status
    statusMessage
}

"Scalar fields defined by EmailSendingAttempt"
enum EmailSendingAttemptScalarFields {
    body
    headers
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    status
    statusMessage
}

"All fields defined by EmailTemplate"
enum EmailTemplateFields {
    comment
    description
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    """

    Name of the template being created. The name can contain alpha-numeric characters, digits and next symbols: .-_~
    """
    name
    template
}

"Scalar fields defined by EmailTemplate"
enum EmailTemplateScalarFields {
    comment
    description
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    """

    Name of the template being created. The name can contain alpha-numeric characters, digits and next symbols: .-_~
    """
    name
    template
}

"All fields defined by EmailVerification"
enum EmailVerificationFields {
    "The verification code that is included in the email sent. Generated by the server, if provided the provided value is ignored"
    code
    "Set by system, cannot be provided"
    confirmed
    email
    email_hypi
    email_type
    email_value
    "Optionally, the email from which the email will be sent. You MUST have a Hypi email app configured to send from this address"
    from
    """

    The HTML contents of the email. This is a Velocity template that will be rendered before being sent.
    The available variables and their types are:
    instance: AppId - You app instance ID
    parent - a map representing the current EmailVerification object
    value - the value of the htmlMessage field
    env: HypiEnv
    """
    htmlMessage
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "Any additional meta data you want to store. For example, you could collect all of the information needed to create the Account"
    meta
    "A plain text version of the email - see this is a velocity template, see htmlMessage for available variables"
    plainTextMessage
    "After the link is clicked from the email, redirect the browser to this URL passing a token in the URL i.e. token=jwt.token.here which can be used get the value in the meta field"
    redirectTo
    "Optionally, the subject of the email, this is a velocity template - Hypi provides a default such as \"Please verify your email to <realm>\""
    subject
    templateName
}

"Scalar fields defined by EmailVerification"
enum EmailVerificationScalarFields {
    "The verification code that is included in the email sent. Generated by the server, if provided the provided value is ignored"
    code
    "Set by system, cannot be provided"
    confirmed
    email_type
    email_value
    "Optionally, the email from which the email will be sent. You MUST have a Hypi email app configured to send from this address"
    from
    """

    The HTML contents of the email. This is a Velocity template that will be rendered before being sent.
    The available variables and their types are:
    instance: AppId - You app instance ID
    parent - a map representing the current EmailVerification object
    value - the value of the htmlMessage field
    env: HypiEnv
    """
    htmlMessage
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "Any additional meta data you want to store. For example, you could collect all of the information needed to create the Account"
    meta
    "A plain text version of the email - see this is a velocity template, see htmlMessage for available variables"
    plainTextMessage
    "After the link is clicked from the email, redirect the browser to this URL passing a token in the URL i.e. token=jwt.token.here which can be used get the value in the meta field"
    redirectTo
    "Optionally, the subject of the email, this is a velocity template - Hypi provides a default such as \"Please verify your email to <realm>\""
    subject
    templateName
}

"Published as part of a subscription event's meta data to indicate the nature of the mutation that resulted in the event being triggered."
enum EventType {
    """

    An event type indicating that the cache entry was created.
    """
    CREATED
    """

    An event type indicating that the cache entry has expired.
    """
    EXPIRED
    """

    An event type indicating that the cache entry was removed.
    """
    REMOVED
    """

    An event type indicating that the cache entry was updated. i.e. a previous mapping existed
    """
    UPDATED
}

"All fields defined by File"
enum FileFields {
    children
    content
    directory
    extension
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    isDirectory
    isSharable
    isStared
    name
    path
    size
    status
    "mime type"
    type
    url
}

"Scalar fields defined by File"
enum FileScalarFields {
    content
    directory
    extension
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    isDirectory
    isSharable
    isStared
    name
    path
    size
    status
    "mime type"
    type
}

enum FileStatus {
    AVAILABLE
    DELETED
    DISABLED
    PENDING_APPROVAL
    PROCESSING
    UNAVAILABLE
    UPLOADED
}

"All fields defined by Gauge"
enum GaugeFields {
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "A human friendly display label for the counter"
    label
    "A name which uniquely identifies this counter in an instance. Must be a letter followed by 0 or more letters, numbers or underscores"
    name
    tags
    "The current value of this gauge, set, increase or decrease as you see fit"
    value
}

"All numeric fields defined by Gauge"
enum GaugeNumericFields {
    value
}

"Scalar fields defined by Gauge"
enum GaugeScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "A human friendly display label for the counter"
    label
    "A name which uniquely identifies this counter in an instance. Must be a letter followed by 0 or more letters, numbers or underscores"
    name
    tags
    "The current value of this gauge, set, increase or decrease as you see fit"
    value
}

enum Gender {
    FEMALE
    MALE
    OTHER
    RATHER_NOT_SAY
}

"All fields defined by GeoEnvelope"
enum GeoEnvelopeFields {
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    p1
    p2
}

"Scalar fields defined by GeoEnvelope"
enum GeoEnvelopeScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
}

"All fields defined by GraphQLRef"
enum GraphQLRefFields {
    field
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    """

    If present this is a set of GraphQL fields that will be selected from the results of the function referenced.
    For example if the type returned by field is "T" and T is the object
    type T {
    a: Int
    b: T2
    }
    type T2 {
    c: String
    }
    then this field can be the selection string:
    a b{c}
    i.e. the GraphQL selection you would use if manually selecting fields from T and T2 WITHOUT any curly braces at the start/end - i.e. no enclosing curlies.
    If not provided, the platform will select hypi{id} meaning the result of this function call will have ONLY the hypi.id field
    """
    selection
    type
}

"Scalar fields defined by GraphQLRef"
enum GraphQLRefScalarFields {
    field
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    """

    If present this is a set of GraphQL fields that will be selected from the results of the function referenced.
    For example if the type returned by field is "T" and T is the object
    type T {
    a: Int
    b: T2
    }
    type T2 {
    c: String
    }
    then this field can be the selection string:
    a b{c}
    i.e. the GraphQL selection you would use if manually selecting fields from T and T2 WITHOUT any curly braces at the start/end - i.e. no enclosing curlies.
    If not provided, the platform will select hypi{id} meaning the result of this function call will have ONLY the hypi.id field
    """
    selection
    type
}

"All fields defined by Group"
enum GroupFields {
    accounts
    children
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "A unique name identifying this group, implicitly sets the path of the group to /<name> whihc can be referenced in wild card permissions"
    name
    organisations
}

"All fields defined by GroupPolicy"
enum GroupPolicyFields {
    groups
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "Positive` or `Negative"
    logic
    name
}

"Scalar fields defined by GroupPolicy"
enum GroupPolicyScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "Positive` or `Negative"
    logic
    name
}

"Scalar fields defined by Group"
enum GroupScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "A unique name identifying this group, implicitly sets the path of the group to /<name> whihc can be referenced in wild card permissions"
    name
}

enum HashAlgorithm {
    BCRYPT
    """

    PKCS i.e. Public Key Cryptography Standards. When used Hypi will encrypt/decrypt the contents using a public/private key pair.
    So the data is encrypted at rest and decrypted whilst in use.
    See https://en.wikipedia.org/wiki/PKCS, specifically Password-based Encryption Standard
    """
    PKCS5
    SHA3
}

enum HttpMethod {
    DELETE
    GET
    HEAD
    OPTIONS
    PATCH
    POST
    PUT
    TRACE
}

"All fields defined by HypiEnv"
enum HypiEnvFields {
    apiHost
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    websocketHost
}

"Scalar fields defined by HypiEnv"
enum HypiEnvScalarFields {
    apiHost
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    websocketHost
}

"All fields defined by Hypi"
enum HypiFields {
    "The ISO8601 date of when the object was created"
    created
    "The ID of the account which created the object"
    createdBy
    """

    An ID automatically generated by the platform for new objects.
    If provided and the ID does not exist, the provided ID is used instead of a generated one and a new entry is inserted
    If provided and the ID already exists then the existing object is updated.
    """
    id
    """

    When you work with interface fields, Hypi is unable to distinguish which implementation you intend to use
    automatically, you must set this field to the name of the implementation of the interface e.g.
    If creating an AccountPolicy which implements the Policy interface, this field should be set to AccountPolicy
    """
    impl
    "The ID of the app instance which created and owns the object"
    instanceId
    "The ISO8601 date of when the object was trashed (if it is currently trashed, null otherwise)"
    trashed
    "The ISO8601 date of when the object was last modified"
    updated
}

"A list of all types in the app which can created or updated directly"
enum HypiMutationType {
    AccessToken
    Account
    AccountPolicy
    Address
    AggFloat
    AggInt
    AggOtherScalar
    AggregatedPolicy
    AppId
    """

    A client defines an agent that acts on behalf of a user/subject.
    Currently implicitly created by Hypi.
    """
    AuthClient
    BruteForceDetectionOptions
    ClientPolicy
    Coordinate
    Counter
    """

    Identifies a given country according to ISO3166
    https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes
    See also https://www.iso.org/obp/ui/#search and
    https://unicode-org.github.io/cldr-staging/charts/37/supplemental/territory_information.html
    """
    Country
    Currency
    Email
    """

    Creates a new outbound message.
    Note that it automatically send unless the autoSend field is false
    https://documentation.Hypi.com/en/latest/api-sending.html#sending
    """
    EmailMessage
    EmailSendingAttempt
    """

    Defines a Hypi template that can be parameterised
    https://documentation.Hypi.com/en/latest/api-templates.html#store-new-template
    """
    EmailTemplate
    EmailVerification
    File
    Gauge
    GeoEnvelope
    "Creates a reference to a GraphQL function in an app instance."
    GraphQLRef
    "Defines a collection for subjects, roles, policies and permissions."
    Group
    GroupPolicy
    Hypi
    HypiEnv
    HypiFilterConnection
    HypiResultEdge
    Image
    Language
    LogMessage
    LoginAttempt
    Notification
    NotificationCtx
    OAuth2AuthorizedClient
    OAuthProvider
    Organisation
    PageInfo
    Pair
    Password
    """

    To reset an Account's password, create a `PasswordReminder`.

    This will generate a code in the `code` field that can be referenced using $!{parent.code} in the `htmlMessage` or `plainTextMessage` fields.

    This will send an email to the email in the `to` field. In the message you should provide a link to a URL where the user can enter their new password.
    Include the code in this URL e.g. https://my-app.com/reset-password?code=$!{parent.code}.

    When the user gets to this page, you will have the password reset code in the URL query string. Get this code from the URL
    and when the user enter their new password, make a POST request to the Hypi API e.g.
    POST <hypi-domain>/email/reset/<domain> - where <domain> is app instance domain.

    In the body of the request send a JSON like this:
    {"code": "<the-code-from-the-URL>", "password": "<the-user's-new-password>"}

    Hypi will change the user's password and return HTTP status 200.
    """
    PasswordReminder
    Permission
    PermissionDescription
    Person
    PersonName
    Phone
    Product
    " namespace for containing authz objects and their relationships."
    Realm
    RealmLink
    RealmPolicy
    RemoteLogin
    "Defines the templates that should be applied to a given HTTP request"
    RequestTemplate
    Role
    RolePolicy
    Script
    ServerlessResponse
    TimePolicy
    URL
    Video
    """

    Defines a web hook that can be used to trigger Hypi GraphQL functions on a given app.
    The account specified in the web hook must have access to the app/instance and must be authorised to call the functions specified.
    """
    Webhook
    """

    If the query or mutation functions in the Webhook definition returns this then it controls what the server responds with
    For example, the GraphQL function can return a 301 or 302 status and a Location header to an external URL to cause a redirect.
    """
    WebhookResponse
    """

    A workflow defines a sequence of steps that execute in a defined order (you set the order field on each step).
    It is one way in which Hypi allows you to do composition, so similarities can be drawn to function composition with some specifics thrown in for Hypi and GraphQL.

    If two steps have the same order their execution order is undefined with relation to each other.
    Every step has a GraphQL function that is executed for that step.

    When a Workflow is executed it creates a WorkflowSession. The result of each step in the workflow is added to the session.

    The first step can have any parameters you want. For the other steps there are some rules that define how the system maps
    parameters to the function in these steps. These rules are:

    1. Any step (including the first step) can have a parameter "params: Json" i.e. name = params and type is Json.
    This params is a map of the arguments passed to the first function in the Workflow. For example if the function was defined as
    step1(a: Int, b: Json, c: MyType): T
    in this case the "params" Json object would be have the fields a, b and c set to the values the function was executed with.
    Normally, this is used in the first step but can be used in any step that wants access to this data.

    2. Any step can have a parameter "session: WorkflowSession" - this is the current workflow's session and contains the results of all steps before the current one.
    You can identify the results for a specific step by finding the result using the step's name in the session's data array.

    3. Except the first step, a parameter "previous: T" where T is the result type of the previous step can be used.
    In this case, the platform will use the output of the previous function for this parameter.
    Note that if the type is not the same as the last step's output type then the workflow will fail if the field is not optional.
    If the field is optional then the platform will not provide it and it would therefore be null if you try to use it.

    4. Except the first step, pass-through is possible. This is where the parameters from the first step are passed through
    to other steps by name and type. i.e. given
    step1(a: Int, b: String): String
    step2(a: Int): ID
    In this case, the variable "a" in both step1 and step2 will have the same value that step1 was executed with.
    Incidentally, this is the same as getting "a" from the "params" Json.
    """
    Workflow
    WorkflowSession
    WorkflowStep
    WorkflowStepData
}

"Scalar fields defined by Hypi"
enum HypiScalarFields {
    "The ISO8601 date of when the object was created"
    created
    "The ID of the account which created the object"
    createdBy
    """

    An ID automatically generated by the platform for new objects.
    If provided and the ID does not exist, the provided ID is used instead of a generated one and a new entry is inserted
    If provided and the ID already exists then the existing object is updated.
    """
    id
    """

    When you work with interface fields, Hypi is unable to distinguish which implementation you intend to use
    automatically, you must set this field to the name of the implementation of the interface e.g.
    If creating an AccountPolicy which implements the Policy interface, this field should be set to AccountPolicy
    """
    impl
    "The ID of the app instance which created and owns the object"
    instanceId
    "The ISO8601 date of when the object was trashed (if it is currently trashed, null otherwise)"
    trashed
    "The ISO8601 date of when the object was last modified"
    updated
}

"A list of all types in the app"
enum HypiSchemaType {
    AccessToken
    Account
    AccountPolicy
    Address
    AggFloat
    AggInt
    AggOtherScalar
    AggregatedPolicy
    AppId
    """

    A client defines an agent that acts on behalf of a user/subject.
    Currently implicitly created by Hypi.
    """
    AuthClient
    BruteForceDetectionOptions
    ClientPolicy
    Coordinate
    Counter
    """

    Identifies a given country according to ISO3166
    https://en.wikipedia.org/wiki/List_of_ISO_3166_country_codes
    See also https://www.iso.org/obp/ui/#search and
    https://unicode-org.github.io/cldr-staging/charts/37/supplemental/territory_information.html
    """
    Country
    Currency
    Email
    """

    Creates a new outbound message.
    Note that it automatically send unless the autoSend field is false
    https://documentation.Hypi.com/en/latest/api-sending.html#sending
    """
    EmailMessage
    EmailSendingAttempt
    """

    Defines a Hypi template that can be parameterised
    https://documentation.Hypi.com/en/latest/api-templates.html#store-new-template
    """
    EmailTemplate
    EmailVerification
    File
    Gauge
    GeoEnvelope
    "Creates a reference to a GraphQL function in an app instance."
    GraphQLRef
    "Defines a collection for subjects, roles, policies and permissions."
    Group
    GroupPolicy
    Hypi
    HypiEnv
    HypiFilterConnection
    HypiResultEdge
    Image
    Language
    LogMessage
    LoginAttempt
    Notification
    NotificationCtx
    OAuth2AuthorizedClient
    OAuthProvider
    Organisation
    PageInfo
    Pair
    Password
    """

    To reset an Account's password, create a `PasswordReminder`.

    This will generate a code in the `code` field that can be referenced using $!{parent.code} in the `htmlMessage` or `plainTextMessage` fields.

    This will send an email to the email in the `to` field. In the message you should provide a link to a URL where the user can enter their new password.
    Include the code in this URL e.g. https://my-app.com/reset-password?code=$!{parent.code}.

    When the user gets to this page, you will have the password reset code in the URL query string. Get this code from the URL
    and when the user enter their new password, make a POST request to the Hypi API e.g.
    POST <hypi-domain>/email/reset/<domain> - where <domain> is app instance domain.

    In the body of the request send a JSON like this:
    {"code": "<the-code-from-the-URL>", "password": "<the-user's-new-password>"}

    Hypi will change the user's password and return HTTP status 200.
    """
    PasswordReminder
    Permission
    PermissionDescription
    Person
    PersonName
    Phone
    Product
    " namespace for containing authz objects and their relationships."
    Realm
    RealmLink
    RealmPolicy
    RemoteLogin
    "Defines the templates that should be applied to a given HTTP request"
    RequestTemplate
    Role
    RolePolicy
    Script
    ServerlessResponse
    TimePolicy
    URL
    Video
    """

    Defines a web hook that can be used to trigger Hypi GraphQL functions on a given app.
    The account specified in the web hook must have access to the app/instance and must be authorised to call the functions specified.
    """
    Webhook
    """

    If the query or mutation functions in the Webhook definition returns this then it controls what the server responds with
    For example, the GraphQL function can return a 301 or 302 status and a Location header to an external URL to cause a redirect.
    """
    WebhookResponse
    """

    A workflow defines a sequence of steps that execute in a defined order (you set the order field on each step).
    It is one way in which Hypi allows you to do composition, so similarities can be drawn to function composition with some specifics thrown in for Hypi and GraphQL.

    If two steps have the same order their execution order is undefined with relation to each other.
    Every step has a GraphQL function that is executed for that step.

    When a Workflow is executed it creates a WorkflowSession. The result of each step in the workflow is added to the session.

    The first step can have any parameters you want. For the other steps there are some rules that define how the system maps
    parameters to the function in these steps. These rules are:

    1. Any step (including the first step) can have a parameter "params: Json" i.e. name = params and type is Json.
    This params is a map of the arguments passed to the first function in the Workflow. For example if the function was defined as
    step1(a: Int, b: Json, c: MyType): T
    in this case the "params" Json object would be have the fields a, b and c set to the values the function was executed with.
    Normally, this is used in the first step but can be used in any step that wants access to this data.

    2. Any step can have a parameter "session: WorkflowSession" - this is the current workflow's session and contains the results of all steps before the current one.
    You can identify the results for a specific step by finding the result using the step's name in the session's data array.

    3. Except the first step, a parameter "previous: T" where T is the result type of the previous step can be used.
    In this case, the platform will use the output of the previous function for this parameter.
    Note that if the type is not the same as the last step's output type then the workflow will fail if the field is not optional.
    If the field is optional then the platform will not provide it and it would therefore be null if you try to use it.

    4. Except the first step, pass-through is possible. This is where the parameters from the first step are passed through
    to other steps by name and type. i.e. given
    step1(a: Int, b: String): String
    step2(a: Int): ID
    In this case, the variable "a" in both step1 and step2 will have the same value that step1 was executed with.
    Incidentally, this is the same as getting "a" from the "params" Json.
    """
    Workflow
    WorkflowSession
    WorkflowStep
    WorkflowStepData
}

"All fields defined by Image"
enum ImageFields {
    description
    file
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    location
    name
}

"Scalar fields defined by Image"
enum ImageScalarFields {
    description
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    name
}

"All fields defined by Language"
enum LanguageFields {
    family
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    iso6391Code
    iso6392BCode
    iso6392TCode
    iso6393Code
    isoName
    nativeName
}

"Scalar fields defined by Language"
enum LanguageScalarFields {
    family
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    iso6391Code
    iso6392BCode
    iso6392TCode
    iso6393Code
    isoName
    nativeName
}

" Logging"
enum LogLevel {
    DEBUG
    ERROR
    INFO
    WARN
}

"All fields defined by LogMessage"
enum LogMessageFields {
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    level
    message
    "Optional, may not be a stacktrace"
    releaseId
    stackTrace
    "This is optional, we can have system messages that aren't from an app"
    type
    "The name of the GraphQL type that the log is for, this is also optional"
    workflow
}

"Scalar fields defined by LogMessage"
enum LogMessageScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    level
    message
    "Optional, may not be a stacktrace"
    releaseId
    stackTrace
    "This is optional, we can have system messages that aren't from an app"
    type
    "The name of the GraphQL type that the log is for, this is also optional"
    workflow
}

"All fields defined by LoginAttempt"
enum LoginAttemptFields {
    errorCode
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    successful
}

"Scalar fields defined by LoginAttempt"
enum LoginAttemptScalarFields {
    errorCode
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    successful
}

"All fields defined by NotificationCtx"
enum NotificationCtxFields {
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    targetAccount
    "The type that the notification applies to"
    type
}

"Scalar fields defined by NotificationCtx"
enum NotificationCtxScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    targetAccount
    "The type that the notification applies to"
    type
}

"All fields defined by Notification"
enum NotificationFields {
    ctx
    ctx_hypi
    ctx_targetAccount
    ctx_type
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    message
}

"Scalar fields defined by Notification"
enum NotificationScalarFields {
    ctx_targetAccount
    ctx_type
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    message
}

"All fields defined by OAuth2AuthorizedClient"
enum OAuth2AuthorizedClientFields {
    accessToken
    clientRegistrationId
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    principalName
    refreshToken
}

"Scalar fields defined by OAuth2AuthorizedClient"
enum OAuth2AuthorizedClientScalarFields {
    accessToken
    clientRegistrationId
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    principalName
    refreshToken
}

"All fields defined by OAuthProvider"
enum OAuthProviderFields {
    authorizationGrantType
    authorizationUri
    clientAuthenticationMethod
    " instanceId-(hypi.id = registrationId)"
    clientId
    clientName
    clientSecret
    configurationMetadata
    hypi
    hypiFailureRedirectUri
    hypiSuccessRedirectUri
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    jwkSetUri
    redirectUriTemplate
    scopes
    tokenUri
    userInfoAuthenticationMethod
    userInfoUri
    userNameAttributeName
}

"Scalar fields defined by OAuthProvider"
enum OAuthProviderScalarFields {
    authorizationGrantType
    authorizationUri
    clientAuthenticationMethod
    " instanceId-(hypi.id = registrationId)"
    clientId
    clientName
    clientSecret
    hypiFailureRedirectUri
    hypiSuccessRedirectUri
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    jwkSetUri
    redirectUriTemplate
    scopes
    tokenUri
    userInfoAuthenticationMethod
    userInfoUri
    userNameAttributeName
}

"The types of GraphQL queries"
enum OpType {
    Mutation
    Query
    Subscription
}

"All fields defined by Organisation"
enum OrganisationFields {
    addresses
    emails
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    incorporated
    logo
    members
    name
    phones
    subsidiaries
}

"Scalar fields defined by Organisation"
enum OrganisationScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    incorporated
    name
}

"All fields defined by Pair"
enum PairFields {
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    key
    value
}

"Scalar fields defined by Pair"
enum PairScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    key
    value
}

"All fields defined by Password"
enum PasswordFields {
    expired
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    """

    password is never returned
    further, the @secret directive enforces this, queries can be use to perform comparison against the field but it is never returned
    """
    value
}

"All fields defined by PasswordReminder"
enum PasswordReminderFields {
    "The verification code that is included in the email sent. Generated by the server, if provided the provided value is ignored"
    code
    "Optionally, the email from which the email will be sent. You MUST have a Hypi email app configured to send from this address"
    from
    """

    The HTML contents of the email. This is a Velocity template that will be rendered before being sent.
    The available variables and their types are:
    instance: AppId - You app instance ID
    parent - a map representing the current EmailVerification object
    value - the value of the htmlMessage field
    env: HypiEnv
    """
    htmlMessage
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "A plain text version of the email - see this is a velocity template, see htmlMessage for available variables"
    plainTextMessage
    "Optionally, the subject of the email, this is a velocity template - Hypi provides a default such as \"Please verify your email to <realm>\""
    subject
    "The Account email that needs to be changed"
    to
    "The Account email that needs to be changed"
    to_hypi
    "The Account email that needs to be changed"
    to_type
    "The Account email that needs to be changed"
    to_value
    "If true the reset code has not yet been used."
    valid
}

"Scalar fields defined by PasswordReminder"
enum PasswordReminderScalarFields {
    "The verification code that is included in the email sent. Generated by the server, if provided the provided value is ignored"
    code
    "Optionally, the email from which the email will be sent. You MUST have a Hypi email app configured to send from this address"
    from
    """

    The HTML contents of the email. This is a Velocity template that will be rendered before being sent.
    The available variables and their types are:
    instance: AppId - You app instance ID
    parent - a map representing the current EmailVerification object
    value - the value of the htmlMessage field
    env: HypiEnv
    """
    htmlMessage
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "A plain text version of the email - see this is a velocity template, see htmlMessage for available variables"
    plainTextMessage
    "Optionally, the subject of the email, this is a velocity template - Hypi provides a default such as \"Please verify your email to <realm>\""
    subject
    "The Account email that needs to be changed"
    to_type
    "The Account email that needs to be changed"
    to_value
    "If true the reset code has not yet been used."
    valid
}

"Scalar fields defined by Password"
enum PasswordScalarFields {
    expired
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    """

    password is never returned
    further, the @secret directive enforces this, queries can be use to perform comparison against the field but it is never returned
    """
    value
}

"All fields defined by PermissionDescription"
enum PermissionDescriptionFields {
    groups
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    organisations
    permissions
    realms
    roles
}

"Scalar fields defined by PermissionDescription"
enum PermissionDescriptionScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
}

"All fields defined by Permission"
enum PermissionFields {
    "defines how the policy arrives at a decision, defaults to Unanimous"
    decisionStrategy
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "If true, this permission grants/denies access to all accounts (including anonymous account)"
    includeAllAccounts
    name
    "Query, Mutation or Subscription"
    operationType
    operations
    policies
    """

    If present then the scopes in this permission will have the given policies applied to this resource.
    This can be used for example to prevent mutation on a resource by a user, group etc
    """
    resource
    scopes
    """

    When a Permission is created, the instance to which it grants access is assumed to be the same as the one in which it is created.
    This means - if this field is not provided, it will be set to the current instance by default.
    Some times, it is necessary to grant permission to a resource that exists in a different instance.
    In those cases, this field can be set to the instance ID from which the resource needs to be accessed.
    It is also possible to set this to the wildcard character '*' - in which case, this permission grants access to the resource from any instance.
    Note that wildcard can only be used to grant access, by default, access is denied to all other instances
    so a negative policy will have no effect when this field is set to '*'.
    """
    targetInstance
    "The type that this permission applies to"
    type
}

"Scalar fields defined by Permission"
enum PermissionScalarFields {
    "defines how the policy arrives at a decision, defaults to Unanimous"
    decisionStrategy
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "If true, this permission grants/denies access to all accounts (including anonymous account)"
    includeAllAccounts
    name
    "Query, Mutation or Subscription"
    operationType
    operations
    """

    If present then the scopes in this permission will have the given policies applied to this resource.
    This can be used for example to prevent mutation on a resource by a user, group etc
    """
    resource
    scopes
    """

    When a Permission is created, the instance to which it grants access is assumed to be the same as the one in which it is created.
    This means - if this field is not provided, it will be set to the current instance by default.
    Some times, it is necessary to grant permission to a resource that exists in a different instance.
    In those cases, this field can be set to the instance ID from which the resource needs to be accessed.
    It is also possible to set this to the wildcard character '*' - in which case, this permission grants access to the resource from any instance.
    Note that wildcard can only be used to grant access, by default, access is denied to all other instances
    so a negative policy will have no effect when this field is set to '*'.
    """
    targetInstance
    "The type that this permission applies to"
    type
}

"All fields defined by Person"
enum PersonFields {
    addresses
    avatar
    dob
    gender
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    names
    phones
    preferences
    roles
}

"All fields defined by PersonName"
enum PersonNameFields {
    firstName
    from
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    lastName
    title
    to
}

"Scalar fields defined by PersonName"
enum PersonNameScalarFields {
    firstName
    from
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    lastName
    title
    to
}

"Scalar fields defined by Person"
enum PersonScalarFields {
    dob
    gender
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
}

"All fields defined by Phone"
enum PhoneFields {
    code
    country
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    number
}

"Scalar fields defined by Phone"
enum PhoneScalarFields {
    code
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    number
}

"All fields defined by Product"
enum ProductFields {
    description
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    price
    title
}

"All numeric fields defined by Product"
enum ProductNumericFields {
    price
}

"Scalar fields defined by Product"
enum ProductScalarFields {
    description
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    price
    title
}

"All fields defined by Realm"
enum RealmFields {
    "If true users can register without an admin creating their account"
    allowRegistrations
    "Optionally defines some options to help detect and protect against brute force login attempts"
    bruteForceDetection
    "The name displayed in the user interface"
    displayName
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    logo
    """

    the name identifying the organisation and becomes the URL by which it is accessed e.g. alpha-corp.hypi.app, where alpha-corp is name
    If not provided one will be automatically generated
    """
    name
    organisations
    referrer
    remoteLoginId
    "if true users must verify their email before they're allowed to login"
    verifyEmail
}

"All fields defined by RealmLink"
enum RealmLinkFields {
    accounts
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    name
}

"Scalar fields defined by RealmLink"
enum RealmLinkScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    name
}

"All fields defined by RealmPolicy"
enum RealmPolicyFields {
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "Positive` or `Negative"
    logic
    name
    realms
}

"Scalar fields defined by RealmPolicy"
enum RealmPolicyScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "Positive` or `Negative"
    logic
    name
}

"Scalar fields defined by Realm"
enum RealmScalarFields {
    "If true users can register without an admin creating their account"
    allowRegistrations
    "The name displayed in the user interface"
    displayName
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    """

    the name identifying the organisation and becomes the URL by which it is accessed e.g. alpha-corp.hypi.app, where alpha-corp is name
    If not provided one will be automatically generated
    """
    name
    referrer
    remoteLoginId
    "if true users must verify their email before they're allowed to login"
    verifyEmail
}

"All fields defined by RemoteLogin"
enum RemoteLoginFields {
    email
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    otherAttributes
    remoteId
    type
}

"Scalar fields defined by RemoteLogin"
enum RemoteLoginScalarFields {
    email
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    otherAttributes
    remoteId
    type
}

"All fields defined by RequestTemplate"
enum RequestTemplateFields {
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    name
    request
    response
}

"Scalar fields defined by RequestTemplate"
enum RequestTemplateScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    name
    request
    response
}

"All fields defined by Role"
enum RoleFields {
    accounts
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    name
}

"All fields defined by RolePolicy"
enum RolePolicyFields {
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "Positive` or `Negative"
    logic
    name
    roles
}

"Scalar fields defined by RolePolicy"
enum RolePolicyScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "Positive` or `Negative"
    logic
    name
}

"Scalar fields defined by Role"
enum RoleScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    name
}

"All fields defined by Script"
enum ScriptFields {
    body
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    name
    type
}

"Scalar fields defined by Script"
enum ScriptScalarFields {
    body
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    name
    type
}

"All fields defined by ServerlessResponse"
enum ServerlessResponseFields {
    attributes
    body
    chunked
    cookies
    files
    headers
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    method
    multiPart
    path
    queryString
}

"Scalar fields defined by ServerlessResponse"
enum ServerlessResponseScalarFields {
    attributes
    body
    chunked
    cookies
    headers
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    method
    multiPart
    path
    queryString
}

"""

One of Hypi's supported Scripting languages. Currently:
1. Groovy
2. JavaScript

Or full serverless functions via KNative, support for OpenWhisk is to come in a future release
"""
enum TanType {
    Groovy
    "Any OpenFaaS function can be used. See a python example at https://docs.openfaas.com/tutorials/first-python-function/"
    OpenFaaS
    OpenWhisk
    "https://velocity.apache.org/engine/2.2/user-guide.html"
    Velocity
}

"All fields defined by TimePolicy"
enum TimePolicyFields {
    accounts
    clients
    "(yyyy-MM-dd hh:mm:ss) can be used for example to ensure a file is not viewable before the given date"
    from
    groups
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "Positive` or `Negative"
    logic
    name
    realms
    roles
    "can be used to ensure a file is not viewable after a given date"
    to
}

"Scalar fields defined by TimePolicy"
enum TimePolicyScalarFields {
    "(yyyy-MM-dd hh:mm:ss) can be used for example to ensure a file is not viewable before the given date"
    from
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "Positive` or `Negative"
    logic
    name
    "can be used to ensure a file is not viewable after a given date"
    to
}

"Time units used in Auth* types"
enum TimeUnit {
    DAYS
    HOURS
    MINUTES
    SECONDS
}

"All fields defined by URL"
enum URLFields {
    host
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    path
    port
    queryParams
}

"All numeric fields defined by URL"
enum URLNumericFields {
    port
}

"Scalar fields defined by URL"
enum URLScalarFields {
    host
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    path
    port
    queryParams
}

enum UserNameAttributeName {
    acr
    amr
    at_hash
    aud
    auth_time
    azp
    c_hash
    exp
    iat
    iss
    nonce
    sub
}

"All fields defined by Video"
enum VideoFields {
    description
    file
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    location
    name
    thumbnails
}

"Scalar fields defined by Video"
enum VideoScalarFields {
    description
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    name
}

"All fields defined by Webhook"
enum WebhookFields {
    """

    Defaults to the account creating the Webhook.
    Hypi will generate an authorisation token automatically for the account when the web hook is triggered.
    This token will then be used to execute the triggers in the web hook (query or mutation).
    For security an account should be created specifically for invoking web hooks and an AccountPolicy should be created that grants access only to the specified functions or otherwise limit the scope of what the account can do.
    """
    as
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "The name by which this web hook is referenced in the URL, if missing the webhook is only adressable by ID"
    name
    """

    This refers to a GraphQL function.
    The function must have a graphql argument defined as `(payload: WebhookPayload): WebhookPayload`
    The function can trigger a workflow or operate on the payload itself.
    """
    query
    """

    This refers to a GraphQL function.
    The function must have a graphql argument defined as `(payload: WebhookPayload): WebhookPayload`
    The function can trigger a workflow or operate on the payload itself.
    """
    query_field
    """

    This refers to a GraphQL function.
    The function must have a graphql argument defined as `(payload: WebhookPayload): WebhookPayload`
    The function can trigger a workflow or operate on the payload itself.
    """
    query_hypi
    """

    This refers to a GraphQL function.
    The function must have a graphql argument defined as `(payload: WebhookPayload): WebhookPayload`
    The function can trigger a workflow or operate on the payload itself.
    """
    query_selection
    """

    This refers to a GraphQL function.
    The function must have a graphql argument defined as `(payload: WebhookPayload): WebhookPayload`
    The function can trigger a workflow or operate on the payload itself.
    """
    query_type
}

"All fields defined by WebhookResponse"
enum WebhookResponseFields {
    body
    headers
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    status
}

"All numeric fields defined by WebhookResponse"
enum WebhookResponseNumericFields {
    status
}

"Scalar fields defined by WebhookResponse"
enum WebhookResponseScalarFields {
    body
    headers
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    status
}

"Scalar fields defined by Webhook"
enum WebhookScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    "The name by which this web hook is referenced in the URL, if missing the webhook is only adressable by ID"
    name
    """

    This refers to a GraphQL function.
    The function must have a graphql argument defined as `(payload: WebhookPayload): WebhookPayload`
    The function can trigger a workflow or operate on the payload itself.
    """
    query_field
    """

    This refers to a GraphQL function.
    The function must have a graphql argument defined as `(payload: WebhookPayload): WebhookPayload`
    The function can trigger a workflow or operate on the payload itself.
    """
    query_selection
    """

    This refers to a GraphQL function.
    The function must have a graphql argument defined as `(payload: WebhookPayload): WebhookPayload`
    The function can trigger a workflow or operate on the payload itself.
    """
    query_type
}

"All fields defined by Workflow"
enum WorkflowFields {
    async
    """

    If present, this is a cron schedule to automatically execute this Workflow
    The syntax as defined at https://www.manpagez.com/man/5/crontab/
    NOTE: The special strings @hourly, @daily etc are NOT supported
    """
    cronSchedule
    evaluateIf
    evaluateIf_field
    evaluateIf_hypi
    evaluateIf_selection
    evaluateIf_type
    """

    An ArcQL query to find the account e.g. hypi.id = 'user123' to find by id or username = 'blah' to find by username
    If present, execution of the steps in the Workflow will be done as this account
    If not specified, it defaults to the account making the request
    """
    execAs
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    """

    Specifies the the max time an async task should be allowed to execute. When this time has elapsed the task will be killed.
    The format is ISO8601 durations https://en.wikipedia.org/wiki/ISO_8601#Durations
    e.g. P1M is 1 month and PT1M is 1 minute
    """
    maxExecutionTime
    name
    "If present AND true, all steps in this block are executed at the same time."
    parallel
    repeatIf
    repeatIf_field
    repeatIf_hypi
    repeatIf_selection
    repeatIf_type
    repeatN
    steps
}

"All numeric fields defined by Workflow"
enum WorkflowNumericFields {
    repeatN
}

"Scalar fields defined by Workflow"
enum WorkflowScalarFields {
    async
    """

    If present, this is a cron schedule to automatically execute this Workflow
    The syntax as defined at https://www.manpagez.com/man/5/crontab/
    NOTE: The special strings @hourly, @daily etc are NOT supported
    """
    cronSchedule
    evaluateIf_field
    evaluateIf_selection
    evaluateIf_type
    """

    An ArcQL query to find the account e.g. hypi.id = 'user123' to find by id or username = 'blah' to find by username
    If present, execution of the steps in the Workflow will be done as this account
    If not specified, it defaults to the account making the request
    """
    execAs
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    """

    Specifies the the max time an async task should be allowed to execute. When this time has elapsed the task will be killed.
    The format is ISO8601 durations https://en.wikipedia.org/wiki/ISO_8601#Durations
    e.g. P1M is 1 month and PT1M is 1 minute
    """
    maxExecutionTime
    name
    "If present AND true, all steps in this block are executed at the same time."
    parallel
    repeatIf_field
    repeatIf_selection
    repeatIf_type
    repeatN
}

"All fields defined by WorkflowSession"
enum WorkflowSessionFields {
    data
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
}

"Scalar fields defined by WorkflowSession"
enum WorkflowSessionScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
}

"All fields defined by WorkflowStepData"
enum WorkflowStepDataFields {
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    stepName
    stepResult
}

"Scalar fields defined by WorkflowStepData"
enum WorkflowStepDataScalarFields {
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    stepName
    stepResult
}

"All fields defined by WorkflowStep"
enum WorkflowStepFields {
    async
    evaluateIf
    evaluateIf_field
    evaluateIf_hypi
    evaluateIf_selection
    evaluateIf_type
    """

    An ArcQL query to find the account e.g. hypi.id = 'user123' to find by id or username = 'blah' to find by username
    If present, execution of the steps in the Workflow will be done as this account
    If not specified, it defaults to the account making the request
    """
    execAs
    "The function to execute for this step, the data returned by the step can subsequently be used in other steps"
    fn
    "The function to execute for this step, the data returned by the step can subsequently be used in other steps"
    fn_field
    "The function to execute for this step, the data returned by the step can subsequently be used in other steps"
    fn_hypi
    "The function to execute for this step, the data returned by the step can subsequently be used in other steps"
    fn_selection
    "The function to execute for this step, the data returned by the step can subsequently be used in other steps"
    fn_type
    hypi
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    """

    Specifies the the max time an async task should be allowed to execute. When this time has elapsed the task will be killed.
    The format is ISO8601 durations https://en.wikipedia.org/wiki/ISO_8601#Durations
    e.g. P1M is 1 month and PT1M is 1 minute
    """
    maxExecutionTime
    "A name that can be used to reference or trigger this step"
    name
    order
    repeatIf
    repeatIf_field
    repeatIf_hypi
    repeatIf_selection
    repeatIf_type
    repeatN
}

"All numeric fields defined by WorkflowStep"
enum WorkflowStepNumericFields {
    order
    repeatN
}

"Scalar fields defined by WorkflowStep"
enum WorkflowStepScalarFields {
    async
    evaluateIf_field
    evaluateIf_selection
    evaluateIf_type
    """

    An ArcQL query to find the account e.g. hypi.id = 'user123' to find by id or username = 'blah' to find by username
    If present, execution of the steps in the Workflow will be done as this account
    If not specified, it defaults to the account making the request
    """
    execAs
    "The function to execute for this step, the data returned by the step can subsequently be used in other steps"
    fn_field
    "The function to execute for this step, the data returned by the step can subsequently be used in other steps"
    fn_selection
    "The function to execute for this step, the data returned by the step can subsequently be used in other steps"
    fn_type
    hypi_created
    hypi_createdBy
    hypi_id
    hypi_impl
    hypi_instanceId
    hypi_trashed
    hypi_updated
    """

    Specifies the the max time an async task should be allowed to execute. When this time has elapsed the task will be killed.
    The format is ISO8601 durations https://en.wikipedia.org/wiki/ISO_8601#Durations
    e.g. P1M is 1 month and PT1M is 1 minute
    """
    maxExecutionTime
    "A name that can be used to reference or trigger this step"
    name
    order
    repeatIf_field
    repeatIf_selection
    repeatIf_type
    repeatN
}

input AccessTokenGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: AccessTokenScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input AccessTokenInput {
    errorCode: String
    errorMsg: String
    hypi: HypiInput
    sessionExpires: Long
    sessionToken: String
}

input AccessTokenInputOpt {
    errorCode: String
    errorMsg: String
    hypi: HypiInputOpt
    sessionExpires: Long
    sessionToken: String
}

input AccountGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: AccountScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input AccountInput {
    attempts: [LoginAttemptInput!]
    emails: [EmailInput!]
    enabled: Boolean
    groups: [GroupInput!]
    hypi: HypiInput
    owner: PersonInput
    password: PasswordInput!
    phones: [PhoneInput!]
    remoteLogins: [RemoteLoginInput!]
    roles: [RoleInput!]
    username: String!
    verified: Boolean
}

input AccountInputOpt {
    attempts: [LoginAttemptInputOpt]
    emails: [EmailInputOpt]
    enabled: Boolean
    groups: [GroupInputOpt]
    hypi: HypiInputOpt
    owner: PersonInputOpt
    password: PasswordInputOpt
    phones: [PhoneInputOpt]
    remoteLogins: [RemoteLoginInputOpt]
    roles: [RoleInputOpt]
    username: String
    verified: Boolean
}

input AccountPolicyGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: AccountPolicyScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input AccountPolicyInput {
    accounts: [AccountInput!]
    hypi: HypiInput
    logic: AuthLogic
    name: String!
}

input AccountPolicyInputOpt {
    accounts: [AccountInputOpt]
    hypi: HypiInputOpt
    logic: AuthLogic
    name: String
}

input AddressGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: AddressScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input AddressInput {
    city: String
    country: CountryInput
    county: String
    door: String
    from: DateTime
    hypi: HypiInput
    postCode: String
    street: String
    to: DateTime
    town: String
}

input AddressInputOpt {
    city: String
    country: CountryInputOpt
    county: String
    door: String
    from: DateTime
    hypi: HypiInputOpt
    postCode: String
    street: String
    to: DateTime
    town: String
}

input AggregatedPolicyGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: AggregatedPolicyScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input AggregatedPolicyInput {
    decisionStrategy: DecisionStrategy
    hypi: HypiInput
    logic: AuthLogic
    name: String!
    policies: [PolicyInput!]!
}

input AggregatedPolicyInputOpt {
    decisionStrategy: DecisionStrategy
    hypi: HypiInputOpt
    logic: AuthLogic
    name: String
    policies: [PolicyInputOpt]
}

input AppIdInput {
    hypi: HypiInput
    name: String!
    realm: String!
    release: String!
}

input AppIdInputOpt {
    hypi: HypiInputOpt
    name: String
    realm: String
    release: String
}

input AuthClientGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: AuthClientScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input AuthClientInput {
    hypi: HypiInput
    name: String!
    secret: String!
}

input AuthClientInputOpt {
    hypi: HypiInputOpt
    name: String
    secret: String
}

input BruteForceDetectionOptionsGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: BruteForceDetectionOptionsScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input BruteForceDetectionOptionsInput {
    failureReset: Int
    failureResetUnit: TimeUnit
    hypi: HypiInput
    maxLoginFailures: Int!
    maxWait: Int
    maxWaitUnit: TimeUnit
    minQuickLoginWait: Int
    minQuickLoginWaitUnit: TimeUnit
    quickLoginCheckMillis: Int
    waitIncrements: Int
    waitIncrementsUnit: TimeUnit
}

input BruteForceDetectionOptionsInputOpt {
    failureReset: Int
    failureResetUnit: TimeUnit
    hypi: HypiInputOpt
    maxLoginFailures: Int
    maxWait: Int
    maxWaitUnit: TimeUnit
    minQuickLoginWait: Int
    minQuickLoginWaitUnit: TimeUnit
    quickLoginCheckMillis: Int
    waitIncrements: Int
    waitIncrementsUnit: TimeUnit
}

input BruteForceDetectionOptionsMaths {
    failureReset: MathInputInt
    maxLoginFailures: MathInputInt
    maxWait: MathInputInt
    minQuickLoginWait: MathInputInt
    quickLoginCheckMillis: MathInputInt
    waitIncrements: MathInputInt
}

input ClientPolicyGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: ClientPolicyScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input ClientPolicyInput {
    clients: [AuthClientInput!]
    hypi: HypiInput
    logic: AuthLogic
    name: String!
}

input ClientPolicyInputOpt {
    clients: [AuthClientInputOpt]
    hypi: HypiInputOpt
    logic: AuthLogic
    name: String
}

input CoordinateGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: CoordinateScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input CoordinateInput {
    hypi: HypiInput
    x: Float!
    y: Float!
}

input CoordinateInputOpt {
    hypi: HypiInputOpt
    x: Float
    y: Float
}

input CoordinateMaths {
    x: MathInputFloat
    y: MathInputFloat
}

input CounterGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: CounterScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input CounterInput {
    hypi: HypiInput
    label: String
    name: String!
    tags: [String!]
    value: Float!
}

input CounterInputOpt {
    hypi: HypiInputOpt
    label: String
    name: String
    tags: [String]
    value: Float
}

input CounterMaths {
    value: MathInputFloat
}

input CountryGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: CountryScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input CountryInput {
    alpha2code: String
    alpha3code: String
    continent: String
    currencies: [CurrencyInput!]
    hypi: HypiInput
    internetCCTLD: String
    languagesSpoken: [LanguageInput!]
    name: String!
    numericCode: String
    officialLanguage: LanguageInput
    sovereignty: String
    stateName: String
    subdivisionCodeLinks: String
}

input CountryInputOpt {
    alpha2code: String
    alpha3code: String
    continent: String
    currencies: [CurrencyInputOpt]
    hypi: HypiInputOpt
    internetCCTLD: String
    languagesSpoken: [LanguageInputOpt]
    name: String
    numericCode: String
    officialLanguage: LanguageInputOpt
    sovereignty: String
    stateName: String
    subdivisionCodeLinks: String
}

input CurrencyGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: CurrencyScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input CurrencyInput {
    code: String!
    hypi: HypiInput
    name: String!
    symbol: String!
}

input CurrencyInputOpt {
    code: String
    hypi: HypiInputOpt
    name: String
    symbol: String
}

input EmailGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: EmailScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input EmailInput {
    hypi: HypiInput
    type: String
    value: String!
}

input EmailInputOpt {
    hypi: HypiInputOpt
    type: String
    value: String
}

input EmailMessageGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: EmailMessageScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input EmailMessageInput {
    attachment: [FileInput!]
    bcc: [EmailInput!]
    cc: [EmailInput!]
    deliveryTime: DateTime
    from: EmailInput!
    headers: Json
    html: String
    hypi: HypiInput
    inline: [FileInput!]
    recipientVariables: Json
    requireTls: Boolean
    responses: [EmailSendingAttemptInput!]
    skipVerification: Boolean
    subject: String!
    tags: [String]
    template: String
    text: String
    to: [EmailInput!]!
    variables: Json
}

input EmailMessageInputOpt {
    attachment: [FileInputOpt]
    bcc: [EmailInputOpt]
    cc: [EmailInputOpt]
    deliveryTime: DateTime
    from: EmailInputOpt
    headers: Json
    html: String
    hypi: HypiInputOpt
    inline: [FileInputOpt]
    recipientVariables: Json
    requireTls: Boolean
    responses: [EmailSendingAttemptInputOpt]
    skipVerification: Boolean
    subject: String
    tags: [String]
    template: String
    text: String
    to: [EmailInputOpt]
    variables: Json
}

input EmailSendingAttemptGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: EmailSendingAttemptScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input EmailSendingAttemptInput {
    body: Json
    headers: Json
    hypi: HypiInput
    status: EmailEventType
    statusMessage: String
}

input EmailSendingAttemptInputOpt {
    body: Json
    headers: Json
    hypi: HypiInputOpt
    status: EmailEventType
    statusMessage: String
}

input EmailTemplateGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: EmailTemplateScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input EmailTemplateInput {
    comment: String
    description: String
    hypi: HypiInput
    name: String
    template: String
}

input EmailTemplateInputOpt {
    comment: String
    description: String
    hypi: HypiInputOpt
    name: String
    template: String
}

input EmailVerificationGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: EmailVerificationScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input EmailVerificationInput {
    code: String
    confirmed: Boolean
    email: EmailInput!
    from: String
    htmlMessage: String
    hypi: HypiInput
    meta: Json
    plainTextMessage: String
    redirectTo: String!
    subject: String
    templateName: String
}

input EmailVerificationInputOpt {
    code: String
    confirmed: Boolean
    email: EmailInputOpt
    from: String
    htmlMessage: String
    hypi: HypiInputOpt
    meta: Json
    plainTextMessage: String
    redirectTo: String
    subject: String
    templateName: String
}

input FileGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: FileScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input FileInput {
    children: [FileInput!]
    content: String
    directory: String!
    extension: String
    hypi: HypiInput
    isDirectory: Boolean!
    isSharable: Boolean
    isStared: Boolean
    name: String!
    path: String!
    size: Long
    status: FileStatus
    type: String
    url: URLInput
}

input FileInputOpt {
    children: [FileInputOpt]
    content: String
    directory: String
    extension: String
    hypi: HypiInputOpt
    isDirectory: Boolean
    isSharable: Boolean
    isStared: Boolean
    name: String
    path: String
    size: Long
    status: FileStatus
    type: String
    url: URLInputOpt
}

input GaugeGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: GaugeScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input GaugeInput {
    hypi: HypiInput
    label: String
    name: String!
    tags: [String!]
    value: Float!
}

input GaugeInputOpt {
    hypi: HypiInputOpt
    label: String
    name: String
    tags: [String]
    value: Float
}

input GaugeMaths {
    value: MathInputFloat
}

input GeoEnvelopeGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: GeoEnvelopeScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input GeoEnvelopeInput {
    hypi: HypiInput
    p1: CoordinateInput!
    p2: CoordinateInput!
}

input GeoEnvelopeInputOpt {
    hypi: HypiInputOpt
    p1: CoordinateInputOpt
    p2: CoordinateInputOpt
}

input GeoInput {
    envelope: GeoEnvelopeInput
    hypi: HypiInput
    srid: Int
}

input GeoInputOpt {
    envelope: GeoEnvelopeInputOpt
    hypi: HypiInputOpt
    srid: Int
}

input GraphQLRefGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: GraphQLRefScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input GraphQLRefInput {
    field: String!
    hypi: HypiInput
    selection: String
    type: OpType!
}

input GraphQLRefInputOpt {
    field: String
    hypi: HypiInputOpt
    selection: String
    type: OpType
}

input GroupGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: GroupScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input GroupInput {
    accounts: [AccountInput!]
    children: [GroupInput!]
    hypi: HypiInput
    name: String!
    organisations: [OrganisationInput!]
}

input GroupInputOpt {
    accounts: [AccountInputOpt]
    children: [GroupInputOpt]
    hypi: HypiInputOpt
    name: String
    organisations: [OrganisationInputOpt]
}

input GroupPolicyGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: GroupPolicyScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input GroupPolicyInput {
    groups: [GroupInput!]
    hypi: HypiInput
    logic: AuthLogic
    name: String!
}

input GroupPolicyInputOpt {
    groups: [GroupInputOpt]
    hypi: HypiInputOpt
    logic: AuthLogic
    name: String
}

input HttpResponseInput {
    headers: Json
    hypi: HypiInput
    rawPayload: String
    status: Int
}

input HttpResponseInputOpt {
    headers: Json
    hypi: HypiInputOpt
    rawPayload: String
    status: Int
}

input HypiInput {
    created: DateTime
    createdBy: ID
    id: ID
    impl: String
    instanceId: String
    trashed: DateTime
    updated: DateTime
}

input HypiInputOpt {
    created: DateTime
    createdBy: ID
    id: ID
    impl: String
    instanceId: String
    trashed: DateTime
    updated: DateTime
}

"A list of types on which mathematical mutations can be performed on"
input HypiMathType {
    BruteForceDetectionOptions: [BruteForceDetectionOptionsMaths!]
    Coordinate: [CoordinateMaths!]
    Counter: [CounterMaths!]
    Gauge: [GaugeMaths!]
    Product: [ProductMaths!]
    URL: [URLMaths!]
    WebhookResponse: [WebhookResponseMaths!]
    Workflow: [WorkflowMaths!]
    WorkflowStep: [WorkflowStepMaths!]
}

"A list of types on which mutations can be performed on"
input HypiUpsertInputUnion {
    AccessToken: [AccessTokenInputOpt!]
    Account: [AccountInputOpt!]
    AccountPolicy: [AccountPolicyInputOpt!]
    Address: [AddressInputOpt!]
    AggregatedPolicy: [AggregatedPolicyInputOpt!]
    AppId: [AppIdInputOpt!]
    AuthClient: [AuthClientInputOpt!]
    BruteForceDetectionOptions: [BruteForceDetectionOptionsInputOpt!]
    ClientPolicy: [ClientPolicyInputOpt!]
    Coordinate: [CoordinateInputOpt!]
    Counter: [CounterInputOpt!]
    Country: [CountryInputOpt!]
    Currency: [CurrencyInputOpt!]
    Email: [EmailInputOpt!]
    EmailMessage: [EmailMessageInputOpt!]
    EmailSendingAttempt: [EmailSendingAttemptInputOpt!]
    EmailTemplate: [EmailTemplateInputOpt!]
    EmailVerification: [EmailVerificationInputOpt!]
    File: [FileInputOpt!]
    Gauge: [GaugeInputOpt!]
    GeoEnvelope: [GeoEnvelopeInputOpt!]
    GraphQLRef: [GraphQLRefInputOpt!]
    Group: [GroupInputOpt!]
    GroupPolicy: [GroupPolicyInputOpt!]
    Hypi: [HypiInputOpt!]
    Image: [ImageInputOpt!]
    Language: [LanguageInputOpt!]
    LogMessage: [LogMessageInputOpt!]
    LoginAttempt: [LoginAttemptInputOpt!]
    Notification: [NotificationInputOpt!]
    NotificationCtx: [NotificationCtxInputOpt!]
    OAuth2AuthorizedClient: [OAuth2AuthorizedClientInputOpt!]
    OAuthProvider: [OAuthProviderInputOpt!]
    Organisation: [OrganisationInputOpt!]
    Pair: [PairInputOpt!]
    Password: [PasswordInputOpt!]
    PasswordReminder: [PasswordReminderInputOpt!]
    Permission: [PermissionInputOpt!]
    Person: [PersonInputOpt!]
    PersonName: [PersonNameInputOpt!]
    Phone: [PhoneInputOpt!]
    Product: [ProductInputOpt!]
    Realm: [RealmInputOpt!]
    RealmLink: [RealmLinkInputOpt!]
    RealmPolicy: [RealmPolicyInputOpt!]
    RemoteLogin: [RemoteLoginInputOpt!]
    RequestTemplate: [RequestTemplateInputOpt!]
    Role: [RoleInputOpt!]
    RolePolicy: [RolePolicyInputOpt!]
    Script: [ScriptInputOpt!]
    ServerlessResponse: [ServerlessResponseInputOpt!]
    TimePolicy: [TimePolicyInputOpt!]
    URL: [URLInputOpt!]
    Video: [VideoInputOpt!]
    Webhook: [WebhookInputOpt!]
    WebhookResponse: [WebhookResponseInputOpt!]
    Workflow: [WorkflowInputOpt!]
    WorkflowSession: [WorkflowSessionInputOpt!]
    WorkflowStep: [WorkflowStepInputOpt!]
    WorkflowStepData: [WorkflowStepDataInputOpt!]
}

input ImageGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: ImageScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input ImageInput {
    description: String
    file: FileInput!
    hypi: HypiInput
    location: GeoInput
    name: String!
}

input ImageInputOpt {
    description: String
    file: FileInputOpt
    hypi: HypiInputOpt
    location: GeoInputOpt
    name: String
}

input InlineHttpRequestTemplate {
    requestTemplate: String
    responseTemplate: String
}

input LanguageGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: LanguageScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input LanguageInput {
    family: String
    hypi: HypiInput
    iso6391Code: String
    iso6392BCode: String
    iso6392TCode: String
    iso6393Code: String
    isoName: String
    nativeName: String
}

input LanguageInputOpt {
    family: String
    hypi: HypiInputOpt
    iso6391Code: String
    iso6392BCode: String
    iso6392TCode: String
    iso6393Code: String
    isoName: String
    nativeName: String
}

input LogMessageGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: LogMessageScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input LogMessageInput {
    hypi: HypiInput
    level: LogLevel!
    message: String
    releaseId: String
    stackTrace: String
    type: String
    workflow: String
}

input LogMessageInputOpt {
    hypi: HypiInputOpt
    level: LogLevel
    message: String
    releaseId: String
    stackTrace: String
    type: String
    workflow: String
}

input LoginAttemptGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: LoginAttemptScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input LoginAttemptInput {
    errorCode: String
    hypi: HypiInput
    successful: Boolean
}

input LoginAttemptInputOpt {
    errorCode: String
    hypi: HypiInputOpt
    successful: Boolean
}

"""

The precedence of the operations follows BODMAS. https://en.wikipedia.org/wiki/Order_of_operations
For clarity if all fields are specified the precedence is:
1. Divsion
2. Multiplication
3. Subtraction
4. Addition
"""
input MathInputFloat {
    div: Float
    hypi: HypiInput!
    minus: Float
    plus: Float
    times: Float
}

"""

The precedence of the operations follows BODMAS. https://en.wikipedia.org/wiki/Order_of_operations
For clarity if all fields are specified the precedence is:
1. Divsion
2. Multiplication
3. Subtraction
4. Addition
"""
input MathInputInt {
    div: Int
    hypi: HypiInput!
    minus: Int
    plus: Int
    times: Int
}

input NotificationCtxGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: NotificationCtxScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input NotificationCtxInput {
    hypi: HypiInput
    targetAccount: ID
    type: String
}

input NotificationCtxInputOpt {
    hypi: HypiInputOpt
    targetAccount: ID
    type: String
}

input NotificationGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: NotificationScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input NotificationInput {
    ctx: NotificationCtxInput
    hypi: HypiInput
    message: String
}

input NotificationInputOpt {
    ctx: NotificationCtxInputOpt
    hypi: HypiInputOpt
    message: String
}

input OAuth2AuthorizedClientGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: OAuth2AuthorizedClientScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input OAuth2AuthorizedClientInput {
    accessToken: String
    clientRegistrationId: String
    hypi: HypiInput
    principalName: String
    refreshToken: String
}

input OAuth2AuthorizedClientInputOpt {
    accessToken: String
    clientRegistrationId: String
    hypi: HypiInputOpt
    principalName: String
    refreshToken: String
}

input OAuthProviderGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: OAuthProviderScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input OAuthProviderInput {
    authorizationGrantType: AuthorizationGrantType
    authorizationUri: String
    clientAuthenticationMethod: ClientAuthenticationMethod
    clientId: String!
    clientName: String
    clientSecret: String!
    configurationMetadata: [PairInput!]
    hypi: HypiInput
    hypiFailureRedirectUri: String
    hypiSuccessRedirectUri: String
    jwkSetUri: String
    redirectUriTemplate: String
    scopes: [String!]
    tokenUri: String
    userInfoAuthenticationMethod: AuthenticationMethod
    userInfoUri: String
    userNameAttributeName: UserNameAttributeName
}

input OAuthProviderInputOpt {
    authorizationGrantType: AuthorizationGrantType
    authorizationUri: String
    clientAuthenticationMethod: ClientAuthenticationMethod
    clientId: String
    clientName: String
    clientSecret: String
    configurationMetadata: [PairInputOpt]
    hypi: HypiInputOpt
    hypiFailureRedirectUri: String
    hypiSuccessRedirectUri: String
    jwkSetUri: String
    redirectUriTemplate: String
    scopes: [String]
    tokenUri: String
    userInfoAuthenticationMethod: AuthenticationMethod
    userInfoUri: String
    userNameAttributeName: UserNameAttributeName
}

input OrganisationGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: OrganisationScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input OrganisationInput {
    addresses: [AddressInput!]
    emails: [EmailInput!]
    hypi: HypiInput
    incorporated: DateTime
    logo: ImageInput
    members: [AccountInput!]
    name: String!
    phones: [PhoneInput!]
    subsidiaries: [OrganisationInput!]
}

input OrganisationInputOpt {
    addresses: [AddressInputOpt]
    emails: [EmailInputOpt]
    hypi: HypiInputOpt
    incorporated: DateTime
    logo: ImageInputOpt
    members: [AccountInputOpt]
    name: String
    phones: [PhoneInputOpt]
    subsidiaries: [OrganisationInputOpt]
}

input PairInput {
    hypi: HypiInput
    key: String
    value: String
}

input PairInputOpt {
    hypi: HypiInputOpt
    key: String
    value: String
}

input PasswordGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: PasswordScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input PasswordInput {
    expired: Boolean
    hypi: HypiInput
    value: String!
}

input PasswordInputOpt {
    expired: Boolean
    hypi: HypiInputOpt
    value: String
}

input PasswordReminderGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: PasswordReminderScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input PasswordReminderInput {
    code: String
    from: String
    htmlMessage: String
    hypi: HypiInput
    plainTextMessage: String
    subject: String
    to: EmailInput!
    valid: Boolean
}

input PasswordReminderInputOpt {
    code: String
    from: String
    htmlMessage: String
    hypi: HypiInputOpt
    plainTextMessage: String
    subject: String
    to: EmailInputOpt
    valid: Boolean
}

input PermissionGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: PermissionScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input PermissionInput {
    decisionStrategy: DecisionStrategy
    hypi: HypiInput
    includeAllAccounts: Boolean
    name: String!
    operationType: OpType!
    operations: [String]!
    policies: [PolicyInput!]
    resource: String
    scopes: [String!]!
    targetInstance: String
    type: String!
}

input PermissionInputOpt {
    decisionStrategy: DecisionStrategy
    hypi: HypiInputOpt
    includeAllAccounts: Boolean
    name: String
    operationType: OpType
    operations: [String]
    policies: [PolicyInputOpt]
    resource: String
    scopes: [String]
    targetInstance: String
    type: String
}

input PermissionRequest {
    from: DateTime
    opType: OpType!
    operationName: String!
    resource: String!
    scopes: [String!]!
    to: DateTime
    type: String!
}

input PersonGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: PersonScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input PersonInput {
    addresses: [AddressInput!]
    avatar: ImageInput
    dob: DateTime
    gender: Gender
    hypi: HypiInput
    names: [PersonNameInput!]!
    phones: [PhoneInput!]
    preferences: [PairInput!]
    roles: [PairInput!]
}

input PersonInputOpt {
    addresses: [AddressInputOpt]
    avatar: ImageInputOpt
    dob: DateTime
    gender: Gender
    hypi: HypiInputOpt
    names: [PersonNameInputOpt]
    phones: [PhoneInputOpt]
    preferences: [PairInputOpt]
    roles: [PairInputOpt]
}

input PersonNameGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: PersonNameScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input PersonNameInput {
    firstName: String
    from: DateTime
    hypi: HypiInput
    lastName: String
    title: String
    to: DateTime
}

input PersonNameInputOpt {
    firstName: String
    from: DateTime
    hypi: HypiInputOpt
    lastName: String
    title: String
    to: DateTime
}

input PhoneGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: PhoneScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input PhoneInput {
    code: String
    country: CountryInput
    hypi: HypiInput
    number: String!
}

input PhoneInputOpt {
    code: String
    country: CountryInputOpt
    hypi: HypiInputOpt
    number: String
}

input PolicyInput {
    accounts: [AccountInput!]
    clients: [AuthClientInput!]
    decisionStrategy: DecisionStrategy
    from: DateTime
    groups: [GroupInput!]
    hypi: HypiInput
    logic: AuthLogic
    name: String!
    policies: [PolicyInput!]
    realms: [RealmLinkInput!]
    roles: [RoleInput!]
    to: DateTime
}

input PolicyInputOpt {
    accounts: [AccountInputOpt]
    clients: [AuthClientInputOpt]
    decisionStrategy: DecisionStrategy
    from: DateTime
    groups: [GroupInputOpt]
    hypi: HypiInputOpt
    logic: AuthLogic
    name: String
    policies: [PolicyInputOpt]
    realms: [RealmLinkInputOpt]
    roles: [RoleInputOpt]
    to: DateTime
}

input ProductGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: ProductScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input ProductInput {
    description: String!
    hypi: HypiInput
    price: Float
    title: String!
}

input ProductInputOpt {
    description: String
    hypi: HypiInputOpt
    price: Float
    title: String
}

input ProductMaths {
    price: MathInputFloat
}

input RealmGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: RealmScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input RealmInput {
    allowRegistrations: Boolean
    bruteForceDetection: BruteForceDetectionOptionsInput
    displayName: String
    hypi: HypiInput
    logo: ImageInput
    name: String
    organisations: [OrganisationInput!]!
    referrer: String
    remoteLoginId: String
    verifyEmail: Boolean
}

input RealmInputOpt {
    allowRegistrations: Boolean
    bruteForceDetection: BruteForceDetectionOptionsInputOpt
    displayName: String
    hypi: HypiInputOpt
    logo: ImageInputOpt
    name: String
    organisations: [OrganisationInputOpt]
    referrer: String
    remoteLoginId: String
    verifyEmail: Boolean
}

input RealmLinkGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: RealmLinkScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input RealmLinkInput {
    accounts: [AccountInput!]!
    hypi: HypiInput
    name: String!
}

input RealmLinkInputOpt {
    accounts: [AccountInputOpt]
    hypi: HypiInputOpt
    name: String
}

input RealmPolicyGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: RealmPolicyScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input RealmPolicyInput {
    hypi: HypiInput
    logic: AuthLogic
    name: String!
    realms: [RealmLinkInput!]
}

input RealmPolicyInputOpt {
    hypi: HypiInputOpt
    logic: AuthLogic
    name: String
    realms: [RealmLinkInputOpt]
}

input RemoteLoginGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: RemoteLoginScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input RemoteLoginInput {
    email: String
    hypi: HypiInput
    otherAttributes: Json
    remoteId: String
    type: String
}

input RemoteLoginInputOpt {
    email: String
    hypi: HypiInputOpt
    otherAttributes: Json
    remoteId: String
    type: String
}

input RequestTemplateGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: RequestTemplateScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input RequestTemplateInput {
    hypi: HypiInput
    name: String!
    request: String
    response: String
}

input RequestTemplateInputOpt {
    hypi: HypiInputOpt
    name: String
    request: String
    response: String
}

input RoleGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: RoleScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input RoleInput {
    accounts: [AccountInput!]
    hypi: HypiInput
    name: String!
}

input RoleInputOpt {
    accounts: [AccountInputOpt]
    hypi: HypiInputOpt
    name: String
}

input RolePolicyGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: RolePolicyScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input RolePolicyInput {
    hypi: HypiInput
    logic: AuthLogic
    name: String!
    roles: [RoleInput!]!
}

input RolePolicyInputOpt {
    hypi: HypiInputOpt
    logic: AuthLogic
    name: String
    roles: [RoleInputOpt]
}

input ScriptGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: ScriptScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input ScriptInput {
    body: String!
    hypi: HypiInput
    name: String!
    type: TanType!
}

input ScriptInputOpt {
    body: String
    hypi: HypiInputOpt
    name: String
    type: TanType
}

input ServerlessResponseGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: ServerlessResponseScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input ServerlessResponseInput {
    attributes: [String]
    body: Json
    chunked: Boolean
    cookies: Json
    files: [FileInput]
    headers: Json
    hypi: HypiInput
    method: String
    multiPart: Boolean
    path: String
    queryString: Json
}

input ServerlessResponseInputOpt {
    attributes: [String]
    body: Json
    chunked: Boolean
    cookies: Json
    files: [FileInputOpt]
    headers: Json
    hypi: HypiInputOpt
    method: String
    multiPart: Boolean
    path: String
    queryString: Json
}

input TimePolicyGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: TimePolicyScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input TimePolicyInput {
    accounts: [AccountInput!]
    clients: [AuthClientInput!]
    from: DateTime
    groups: [GroupInput!]
    hypi: HypiInput
    logic: AuthLogic
    name: String!
    realms: [RealmLinkInput!]
    roles: [RoleInput!]
    to: DateTime
}

input TimePolicyInputOpt {
    accounts: [AccountInputOpt]
    clients: [AuthClientInputOpt]
    from: DateTime
    groups: [GroupInputOpt]
    hypi: HypiInputOpt
    logic: AuthLogic
    name: String
    realms: [RealmLinkInputOpt]
    roles: [RoleInputOpt]
    to: DateTime
}

input Trigger {
    """

    Executed asynchronously after the target. It MUST have the same arguments as the target and can optionally
    have an argument called "hypiResult: T" where T is the type returned by the target
    """
    after: GraphQLRefInput
    """

    Executes before the target function. Typically used for validation to prevent execution of a function.
    It MUST have the same arguments as the target function and return Boolean
    """
    before: GraphQLRefInput
}

input URLGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: URLScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input URLInput {
    host: String
    hypi: HypiInput
    path: String!
    port: Int
    queryParams: Json
}

input URLInputOpt {
    host: String
    hypi: HypiInputOpt
    path: String
    port: Int
    queryParams: Json
}

input URLMaths {
    port: MathInputInt
}

input VideoGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: VideoScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input VideoInput {
    description: String
    file: FileInput!
    hypi: HypiInput
    location: GeoInput
    name: String!
    thumbnails: [ImageInput!]
}

input VideoInputOpt {
    description: String
    file: FileInputOpt
    hypi: HypiInputOpt
    location: GeoInputOpt
    name: String
    thumbnails: [ImageInputOpt]
}

input WebhookGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: WebhookScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input WebhookInput {
    as: AccountInput
    hypi: HypiInput
    name: String
    query: GraphQLRefInput!
}

input WebhookInputOpt {
    as: AccountInputOpt
    hypi: HypiInputOpt
    name: String
    query: GraphQLRefInputOpt
}

input WebhookPayload {
    body: String
    headers: Json!
    url: URLInput!
}

input WebhookResponseGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: WebhookResponseScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input WebhookResponseInput {
    body: Json
    headers: Json
    hypi: HypiInput
    status: Int
}

input WebhookResponseInputOpt {
    body: Json
    headers: Json
    hypi: HypiInputOpt
    status: Int
}

input WebhookResponseMaths {
    status: MathInputInt
}

input WorkflowAsyncInput {
    async: Boolean
    cronSchedule: String
    evaluateIf: GraphQLRefInput
    execAs: String
    fn: GraphQLRefInput
    hypi: HypiInput
    maxExecutionTime: String
    name: String
    order: Int
    parallel: Boolean
    repeatIf: GraphQLRefInput
    repeatN: Int
    steps: [WorkflowStepInput!]
}

input WorkflowAsyncInputOpt {
    async: Boolean
    cronSchedule: String
    evaluateIf: GraphQLRefInputOpt
    execAs: String
    fn: GraphQLRefInputOpt
    hypi: HypiInputOpt
    maxExecutionTime: String
    name: String
    order: Int
    parallel: Boolean
    repeatIf: GraphQLRefInputOpt
    repeatN: Int
    steps: [WorkflowStepInputOpt]
}

input WorkflowConditionalInput {
    async: Boolean
    cronSchedule: String
    evaluateIf: GraphQLRefInput
    execAs: String
    fn: GraphQLRefInput
    hypi: HypiInput
    maxExecutionTime: String
    name: String
    order: Int
    parallel: Boolean
    repeatIf: GraphQLRefInput
    repeatN: Int
    steps: [WorkflowStepInput!]
}

input WorkflowConditionalInputOpt {
    async: Boolean
    cronSchedule: String
    evaluateIf: GraphQLRefInputOpt
    execAs: String
    fn: GraphQLRefInputOpt
    hypi: HypiInputOpt
    maxExecutionTime: String
    name: String
    order: Int
    parallel: Boolean
    repeatIf: GraphQLRefInputOpt
    repeatN: Int
    steps: [WorkflowStepInputOpt]
}

input WorkflowExecutableAsInput {
    async: Boolean
    cronSchedule: String
    evaluateIf: GraphQLRefInput
    execAs: String
    fn: GraphQLRefInput
    hypi: HypiInput
    maxExecutionTime: String
    name: String
    order: Int
    parallel: Boolean
    repeatIf: GraphQLRefInput
    repeatN: Int
    steps: [WorkflowStepInput!]
}

input WorkflowExecutableAsInputOpt {
    async: Boolean
    cronSchedule: String
    evaluateIf: GraphQLRefInputOpt
    execAs: String
    fn: GraphQLRefInputOpt
    hypi: HypiInputOpt
    maxExecutionTime: String
    name: String
    order: Int
    parallel: Boolean
    repeatIf: GraphQLRefInputOpt
    repeatN: Int
    steps: [WorkflowStepInputOpt]
}

input WorkflowGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: WorkflowScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input WorkflowInput {
    async: Boolean
    cronSchedule: String
    evaluateIf: GraphQLRefInput
    execAs: String
    hypi: HypiInput
    maxExecutionTime: String
    name: String!
    parallel: Boolean
    repeatIf: GraphQLRefInput
    repeatN: Int
    steps: [WorkflowStepInput!]
}

input WorkflowInputOpt {
    async: Boolean
    cronSchedule: String
    evaluateIf: GraphQLRefInputOpt
    execAs: String
    hypi: HypiInputOpt
    maxExecutionTime: String
    name: String
    parallel: Boolean
    repeatIf: GraphQLRefInputOpt
    repeatN: Int
    steps: [WorkflowStepInputOpt]
}

input WorkflowMaths {
    repeatN: MathInputInt
}

input WorkflowOrderedInput {
    async: Boolean
    evaluateIf: GraphQLRefInput
    execAs: String
    fn: GraphQLRefInput
    hypi: HypiInput
    maxExecutionTime: String
    name: String
    order: Int!
    repeatIf: GraphQLRefInput
    repeatN: Int
}

input WorkflowOrderedInputOpt {
    async: Boolean
    evaluateIf: GraphQLRefInputOpt
    execAs: String
    fn: GraphQLRefInputOpt
    hypi: HypiInputOpt
    maxExecutionTime: String
    name: String
    order: Int
    repeatIf: GraphQLRefInputOpt
    repeatN: Int
}

input WorkflowParallelInput {
    async: Boolean
    cronSchedule: String
    evaluateIf: GraphQLRefInput
    execAs: String
    hypi: HypiInput
    maxExecutionTime: String
    name: String
    parallel: Boolean
    repeatIf: GraphQLRefInput
    repeatN: Int
    steps: [WorkflowStepInput!]
}

input WorkflowParallelInputOpt {
    async: Boolean
    cronSchedule: String
    evaluateIf: GraphQLRefInputOpt
    execAs: String
    hypi: HypiInputOpt
    maxExecutionTime: String
    name: String
    parallel: Boolean
    repeatIf: GraphQLRefInputOpt
    repeatN: Int
    steps: [WorkflowStepInputOpt]
}

input WorkflowRepeatableInput {
    async: Boolean
    cronSchedule: String
    evaluateIf: GraphQLRefInput
    execAs: String
    fn: GraphQLRefInput
    hypi: HypiInput
    maxExecutionTime: String
    name: String
    order: Int
    parallel: Boolean
    repeatIf: GraphQLRefInput
    repeatN: Int
    steps: [WorkflowStepInput!]
}

input WorkflowRepeatableInputOpt {
    async: Boolean
    cronSchedule: String
    evaluateIf: GraphQLRefInputOpt
    execAs: String
    fn: GraphQLRefInputOpt
    hypi: HypiInputOpt
    maxExecutionTime: String
    name: String
    order: Int
    parallel: Boolean
    repeatIf: GraphQLRefInputOpt
    repeatN: Int
    steps: [WorkflowStepInputOpt]
}

input WorkflowSessionGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: WorkflowSessionScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input WorkflowSessionInput {
    data: [WorkflowStepDataInput!]
    hypi: HypiInput
}

input WorkflowSessionInputOpt {
    data: [WorkflowStepDataInputOpt]
    hypi: HypiInputOpt
}

input WorkflowStepDataGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: WorkflowStepDataScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input WorkflowStepDataInput {
    hypi: HypiInput
    stepName: String!
    stepResult: Any!
}

input WorkflowStepDataInputOpt {
    hypi: HypiInputOpt
    stepName: String
    stepResult: Any
}

input WorkflowStepGroupByOptions {
    "Applies only to DateTime fields. If provided then the date is grouped to this granularity e.g. if MINUTES then the grouping will be per minute"
    dateGranularity: TimeUnit
    "The field by which to to group the matching data"
    field: WorkflowStepScalarFields!
    "If provided, the aggregated data will be ordered by this field and any other field which specifies this field, in the order they're defined"
    order: AggOrder
}

input WorkflowStepInput {
    async: Boolean
    evaluateIf: GraphQLRefInput
    execAs: String
    fn: GraphQLRefInput!
    hypi: HypiInput
    maxExecutionTime: String
    name: String
    order: Int!
    repeatIf: GraphQLRefInput
    repeatN: Int
}

input WorkflowStepInputOpt {
    async: Boolean
    evaluateIf: GraphQLRefInputOpt
    execAs: String
    fn: GraphQLRefInputOpt
    hypi: HypiInputOpt
    maxExecutionTime: String
    name: String
    order: Int
    repeatIf: GraphQLRefInputOpt
    repeatN: Int
}

input WorkflowStepMaths {
    order: MathInputInt
    repeatN: MathInputInt
}

input WorkflowTimedInput {
    async: Boolean
    cronSchedule: String
    evaluateIf: GraphQLRefInput
    execAs: String
    fn: GraphQLRefInput
    hypi: HypiInput
    maxExecutionTime: String
    name: String
    order: Int
    parallel: Boolean
    repeatIf: GraphQLRefInput
    repeatN: Int
    steps: [WorkflowStepInput!]
}

input WorkflowTimedInputOpt {
    async: Boolean
    cronSchedule: String
    evaluateIf: GraphQLRefInputOpt
    execAs: String
    fn: GraphQLRefInputOpt
    hypi: HypiInputOpt
    maxExecutionTime: String
    name: String
    order: Int
    parallel: Boolean
    repeatIf: GraphQLRefInputOpt
    repeatN: Int
    steps: [WorkflowStepInputOpt]
}


"DateTime scalar"
scalar DateTime

"JSON scalar"
scalar Json

"Any scalar. DO NOT USE except in extremely rare cases where it is unavoidable to do so"
scalar Any

"Long type"
scalar Long